{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.chdir('C:/Users/emigi/OneDrive/Desktop/Dissertation/Analysis Files/NLP Part')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_trial_df = pd.read_excel('Fake News 10000 1700 Classified.xlsx')\n",
    "\n",
    "articles_text = pd.read_excel(\"10000ish Articles Text.xlsx\")\n",
    "\n",
    "first_trial_df['Article Text'] = articles_text.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_one_percent_labelled = pd.read_excel('Sample One Percent Italian Fakenews Party Labelled Naively.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emigi\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "party = []\n",
    "\n",
    "for text in first_trial_df['Article Text'].iloc[1786:]:\n",
    "    if not isinstance(text, str):\n",
    "        party.append(np.nan)\n",
    "    else:\n",
    "        L_count = text.count('Lega') + text.count('lega')\n",
    "        M5_count = text.count('Movimento 5 stelle') + text.count('Movimento 5 Stelle') + text.count('movimento 5 stelle')\n",
    "        PD_count = text.count('Partito Democratico') + text.count('partito democratico')\n",
    "        FI_count = text.count('Forza Italia') + text.count('forza italia')\n",
    "        if L_count > M5_count + PD_count + FI_count:\n",
    "            party.append('L')\n",
    "        elif M5_count > L_count + PD_count + FI_count:\n",
    "            party.append('M5')\n",
    "        elif FI_count > L_count + PD_count + M5_count:\n",
    "            party.append('FI')\n",
    "        elif PD_count > M5_count + L_count + FI_count:\n",
    "            party.append('PD')\n",
    "        else:\n",
    "            party.append('O')\n",
    "            \n",
    "first_trial_df.Party.iloc[1786:] = party\n",
    "\n",
    "## Filtering out the nan\n",
    "\n",
    "first_trial_df = first_trial_df.dropna(subset=['Party'])\n",
    "\n",
    "## Creating a whole dataset\n",
    "\n",
    "frames = [first_trial_df, sample_one_percent_labelled]\n",
    "\n",
    "final_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "import math\n",
    "import operator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import nltk\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D, merge, Masking,TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.layers import concatenate\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing first iteration\n",
    "\n",
    "glove_path = 'C:/Users/emigi/OneDrive/Desktop/Dissertation/Analysis Files/NLP Part/glove_WIKI'\n",
    "\n",
    "glove_model = Word2Vec.load('glove_WIKI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the italian word embeddings\n",
    "\n",
    "## Create a dictionary covering all possible words in the sample\n",
    "\n",
    "starting_train = final_df.dropna(subset=['Sentiment'])\n",
    "\n",
    "starting_train = starting_train[starting_train['Article Text'] != 0]\n",
    "starting_train = starting_train.dropna(subset=['Article Text'])\n",
    "final_df = final_df[final_df['Article Text'] != 0]\n",
    "final_df = final_df.dropna(subset=['Article Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining initial train and test\n",
    "\n",
    "final_df = pd.read_excel('Final Df Advanced Italian News.xlsx')\n",
    "\n",
    "def train_test_division(starting_train, df, division_percentage):\n",
    "    n = starting_train.shape[0]\n",
    "    n_test = int((n / division_percentage[0])*division_percentage[1])\n",
    "    test_data = df.iloc[n:(n+n_test)+1, :]\n",
    "    return (starting_train, test_data)\n",
    "\n",
    "starting_train, starting_test = train_test_division(starting_train, final_df, (0.7, 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "  \n",
    "def model_bilstm_attention(embedding_matrix):\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    l = Bidirectional(LSTM(64, return_sequences=True, go_backwards=True))(x)\n",
    "    g = Bidirectional(GRU(64, return_sequences=True))(x)\n",
    "    x = concatenate([l, g])\n",
    "    x = Bidirectional(LSTM(64//2, return_sequences=True))(x)\n",
    "    \n",
    "    \n",
    "    # x1 = Attention(maxlen)(x)\n",
    "    x2 = GlobalAveragePooling1D()(x)\n",
    "    x3 = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    x = Concatenate()([x2, x3])\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    outp = Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def formatting_matrix_X(starting_train_df):\n",
    "    \n",
    "    \n",
    "    ## Get the top 50 words in order of presence and get their vector\n",
    "    ## Then, compute the mean of each\n",
    "    word_embedding_X = np.ones(10)\n",
    "    itera = 0\n",
    "    for d in starting_train_df['Dictionary Words']:\n",
    "        means_array = []\n",
    "        sort_dict = sorted(d, key=d.get, reverse=True)\n",
    "        top_10 = sort_dict[:10]      ## 10 values for each article\n",
    "        for word in top_10: \n",
    "            try:\n",
    "                word_vector = glove_model.wv[word]\n",
    "                mean = np.mean(word_vector)\n",
    "                means_array.append(mean)\n",
    "                itera += 1\n",
    "            except:\n",
    "                pass  \n",
    "        print(itera)                                \n",
    "        \n",
    "        if len(means_array) < 10:\n",
    "            print(f'Length of means_array : {len(means_array)}')\n",
    "            means_array = means_array + [np.mean(means_array)]*(10 - len(means_array))\n",
    "           \n",
    "        \n",
    "        means_array = np.array(means_array)\n",
    "        word_embedding_X = np.vstack((word_embedding_X, means_array))\n",
    "    ## Dropping the first column\n",
    "    formatting_matrix_X = np.delete(word_embedding_X, 0, 0)\n",
    "    return formatting_matrix_X\n",
    "\n",
    "\n",
    "def word_embedding(df):\n",
    "    \n",
    "    articles = df['Article Text']\n",
    "    general_vectors_distr = []\n",
    "    mem_l = []\n",
    "    nb_words = 0\n",
    "    iterat1 = 0\n",
    "    for art in articles:\n",
    "        tokens = nltk.word_tokenize(art, language='italian')\n",
    "        for t in tokens:\n",
    "            try:\n",
    "                word_vector = glove_model.wv[t]\n",
    "                general_vectors_distr.append(word_vector)\n",
    "                if t in mem_l:\n",
    "                    pass\n",
    "                else:\n",
    "                    mem_l.append(t)\n",
    "                    nb_words += 1\n",
    "            except:\n",
    "                pass\n",
    "        # print(iterat1)\n",
    "        iterat1 += 1\n",
    "      \n",
    "    all_embs = np.stack(general_vectors_distr)  \n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()    \n",
    "    embed_size = all_embs.shape[1]\n",
    "    \n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    ## filling the embedding matrix\n",
    "    iterat2 = 0\n",
    "    for token, i in zip(mem_l, range(nb_words)):\n",
    "        embedding_matrix[i] = glove_model[token]\n",
    "        # print(iterat2)\n",
    "        iterat2 += 1\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emigi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "word_embedding_starting_df = word_embedding(pd.concat([starting_train, starting_test])) ## Loading Word Embeddings\n",
    "# pd.DataFrame(word_embedding_starting_df).to_excel('Word Embedding Starting Dataset.xslx')\n",
    "starting_train_X = starting_train['Article Text']\n",
    "starting_test_X = starting_test['Article Text']\n",
    "starting_train_Y = starting_train['Sentiment']\n",
    "starting_test_Y = starting_test['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 12022 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in an article to use\n",
    "\n",
    "## To input into the neural network, we must first tokenize the sentences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(starting_train_X))\n",
    "train_X = tokenizer.texts_to_sequences(starting_train_X)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(starting_test_X))\n",
    "test_X = tokenizer.texts_to_sequences(starting_test_X)\n",
    "\n",
    "## Pad the sequences\n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 300)     3606600     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 100, 300)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 100, 128)     186880      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 100, 128)     140160      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 100, 256)     0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 100, 64)      73984       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 64)           0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 64)           0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           2064        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            17          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,009,705\n",
      "Trainable params: 403,105\n",
      "Non-trainable params: 3,606,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Converting the output shape to categoricals\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "## converting the bad sentiment (i.e. -1, to 2)\n",
    "\n",
    "starting_train_Y[starting_train_Y == -1] = 2\n",
    "\n",
    "train_Y = to_categorical(starting_train_Y)\n",
    "\n",
    "embedding_matrix = np.mean([word_embedding_starting_df], axis = 0)\n",
    "np.shape(embedding_matrix)\n",
    "model = model_bilstm_attention(embedding_matrix)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting the model with 1 epoch and with dummy for 0 sentiment\n",
    "## Given the initial distribution of sentiments : <200 for -1 and approx. 200 for class 1\n",
    "## I will use class weight function\n",
    "class_weight = {0 : 1.15,\n",
    "                1 : 0.85}\n",
    "class_weight_negatives = {0 : 1.,\n",
    "                          1 : 2.4}\n",
    "class_weight_positives = {0 : 1.,\n",
    "                          1 : 1.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1036 samples, validate on 260 samples\n",
      "Epoch 1/20\n",
      "1036/1036 [==============================] - 6s 6ms/step - loss: 0.6535 - accuracy: 0.6515 - val_loss: 0.5061 - val_accuracy: 0.9654\n",
      "Epoch 2/20\n",
      "1036/1036 [==============================] - 4s 3ms/step - loss: 0.6517 - accuracy: 0.6496 - val_loss: 0.4897 - val_accuracy: 0.9654\n",
      "Epoch 3/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6568 - accuracy: 0.6448 - val_loss: 0.4862 - val_accuracy: 0.9654\n",
      "Epoch 4/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6502 - accuracy: 0.6506 - val_loss: 0.4462 - val_accuracy: 0.9654\n",
      "Epoch 5/20\n",
      "1036/1036 [==============================] - 4s 3ms/step - loss: 0.6538 - accuracy: 0.6506 - val_loss: 0.4911 - val_accuracy: 0.9654\n",
      "Epoch 6/20\n",
      "1036/1036 [==============================] - 4s 3ms/step - loss: 0.6485 - accuracy: 0.6506 - val_loss: 0.4933 - val_accuracy: 0.9654\n",
      "Epoch 7/20\n",
      "1036/1036 [==============================] - 4s 3ms/step - loss: 0.6456 - accuracy: 0.6506 - val_loss: 0.4699 - val_accuracy: 0.9654\n",
      "Epoch 8/20\n",
      "1036/1036 [==============================] - 4s 3ms/step - loss: 0.6448 - accuracy: 0.6506 - val_loss: 0.5043 - val_accuracy: 0.9654\n",
      "Epoch 9/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6428 - accuracy: 0.6506 - val_loss: 0.4853 - val_accuracy: 0.9654\n",
      "Epoch 10/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6384 - accuracy: 0.6506 - val_loss: 0.4750 - val_accuracy: 0.9654\n",
      "Epoch 11/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6324 - accuracy: 0.6506 - val_loss: 0.4534 - val_accuracy: 0.9654\n",
      "Epoch 12/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6313 - accuracy: 0.6525 - val_loss: 0.5518 - val_accuracy: 0.6500\n",
      "Epoch 13/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6341 - accuracy: 0.6361 - val_loss: 0.4694 - val_accuracy: 0.9192\n",
      "Epoch 14/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6216 - accuracy: 0.6477 - val_loss: 0.5853 - val_accuracy: 0.4115\n",
      "Epoch 15/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6176 - accuracy: 0.6583 - val_loss: 0.4092 - val_accuracy: 0.9654\n",
      "Epoch 16/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6061 - accuracy: 0.6680 - val_loss: 0.5186 - val_accuracy: 0.6808\n",
      "Epoch 17/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6024 - accuracy: 0.6438 - val_loss: 0.4067 - val_accuracy: 0.8692\n",
      "Epoch 18/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6007 - accuracy: 0.6506 - val_loss: 0.5122 - val_accuracy: 0.6423\n",
      "Epoch 19/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.5973 - accuracy: 0.6525 - val_loss: 0.4104 - val_accuracy: 0.8231\n",
      "Epoch 20/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6015 - accuracy: 0.6525 - val_loss: 0.5676 - val_accuracy: 0.4692\n",
      "Train on 1036 samples, validate on 260 samples\n",
      "Epoch 1/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7611 - accuracy: 0.7481 - val_loss: 0.4541 - val_accuracy: 0.9769\n",
      "Epoch 2/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7444 - accuracy: 0.7915 - val_loss: 0.4060 - val_accuracy: 0.9769\n",
      "Epoch 3/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7364 - accuracy: 0.7915 - val_loss: 0.4887 - val_accuracy: 0.9769\n",
      "Epoch 4/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7401 - accuracy: 0.7915 - val_loss: 0.4312 - val_accuracy: 0.9769\n",
      "Epoch 5/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7334 - accuracy: 0.7915 - val_loss: 0.4247 - val_accuracy: 0.9769\n",
      "Epoch 6/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7341 - accuracy: 0.7915 - val_loss: 0.4466 - val_accuracy: 0.9769\n",
      "Epoch 7/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7371 - accuracy: 0.7915 - val_loss: 0.4441 - val_accuracy: 0.9769\n",
      "Epoch 8/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7324 - accuracy: 0.7915 - val_loss: 0.4505 - val_accuracy: 0.9769\n",
      "Epoch 9/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7347 - accuracy: 0.7905 - val_loss: 0.4779 - val_accuracy: 0.9769\n",
      "Epoch 10/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7280 - accuracy: 0.7915 - val_loss: 0.4722 - val_accuracy: 0.9769\n",
      "Epoch 11/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7107 - accuracy: 0.7915 - val_loss: 0.4323 - val_accuracy: 0.9769\n",
      "Epoch 12/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7112 - accuracy: 0.7905 - val_loss: 0.3615 - val_accuracy: 0.9769\n",
      "Epoch 13/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7223 - accuracy: 0.7790 - val_loss: 0.3861 - val_accuracy: 0.9769\n",
      "Epoch 14/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7168 - accuracy: 0.7915 - val_loss: 0.4298 - val_accuracy: 0.9769\n",
      "Epoch 15/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6913 - accuracy: 0.7915 - val_loss: 0.4597 - val_accuracy: 0.9769\n",
      "Epoch 16/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6855 - accuracy: 0.7915 - val_loss: 0.2791 - val_accuracy: 0.9769\n",
      "Epoch 17/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6752 - accuracy: 0.7915 - val_loss: 0.4725 - val_accuracy: 0.9769\n",
      "Epoch 18/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6763 - accuracy: 0.7915 - val_loss: 0.5181 - val_accuracy: 0.9769\n",
      "Epoch 19/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6732 - accuracy: 0.7915 - val_loss: 0.4465 - val_accuracy: 0.9769\n",
      "Epoch 20/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6446 - accuracy: 0.7915 - val_loss: 0.4964 - val_accuracy: 0.9769\n",
      "Train on 1036 samples, validate on 260 samples\n",
      "Epoch 1/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7529 - accuracy: 0.8591 - val_loss: 0.3961 - val_accuracy: 0.9885\n",
      "Epoch 2/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7250 - accuracy: 0.8591 - val_loss: 0.3927 - val_accuracy: 0.9885\n",
      "Epoch 3/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7176 - accuracy: 0.8591 - val_loss: 0.4114 - val_accuracy: 0.9885\n",
      "Epoch 4/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7202 - accuracy: 0.8591 - val_loss: 0.3615 - val_accuracy: 0.9885\n",
      "Epoch 5/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7112 - accuracy: 0.8591 - val_loss: 0.4108 - val_accuracy: 0.9885\n",
      "Epoch 6/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7102 - accuracy: 0.8591 - val_loss: 0.3659 - val_accuracy: 0.9885\n",
      "Epoch 7/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.7089 - accuracy: 0.8591 - val_loss: 0.3618 - val_accuracy: 0.9885\n",
      "Epoch 8/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6953 - accuracy: 0.8591 - val_loss: 0.3686 - val_accuracy: 0.9885\n",
      "Epoch 9/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6793 - accuracy: 0.8591 - val_loss: 0.3334 - val_accuracy: 0.9885\n",
      "Epoch 10/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6797 - accuracy: 0.8591 - val_loss: 0.2930 - val_accuracy: 0.9885\n",
      "Epoch 11/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6680 - accuracy: 0.8591 - val_loss: 0.3649 - val_accuracy: 0.9885\n",
      "Epoch 12/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6543 - accuracy: 0.8591 - val_loss: 0.3521 - val_accuracy: 0.9885\n",
      "Epoch 13/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6429 - accuracy: 0.8591 - val_loss: 0.3247 - val_accuracy: 0.9885\n",
      "Epoch 14/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6409 - accuracy: 0.8591 - val_loss: 0.3660 - val_accuracy: 0.9885\n",
      "Epoch 15/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6343 - accuracy: 0.8591 - val_loss: 0.2915 - val_accuracy: 0.9885\n",
      "Epoch 16/20\n",
      "1036/1036 [==============================] - 5s 5ms/step - loss: 0.6276 - accuracy: 0.8591 - val_loss: 0.3645 - val_accuracy: 0.9885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6174 - accuracy: 0.8591 - val_loss: 0.3480 - val_accuracy: 0.9885\n",
      "Epoch 18/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6174 - accuracy: 0.8591 - val_loss: 0.3723 - val_accuracy: 0.9885\n",
      "Epoch 19/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6151 - accuracy: 0.8591 - val_loss: 0.3744 - val_accuracy: 0.9885\n",
      "Epoch 20/20\n",
      "1036/1036 [==============================] - 4s 4ms/step - loss: 0.6048 - accuracy: 0.8591 - val_loss: 0.3907 - val_accuracy: 0.9885\n"
     ]
    }
   ],
   "source": [
    "## Generating three different models for neutrals, positives and negatives, respectively\n",
    "\n",
    "res_pred = model.fit(train_X, train_Y[:, 0], validation_split=0.2, epochs=20, class_weight = class_weight)\n",
    "pred_test_x = model.predict(test_X)\n",
    "res_pred_pos = model.fit(train_X, train_Y[:, 1], validation_split=0.2, epochs=20, class_weight = class_weight_positives)\n",
    "pred_test_x_ones = model.predict(test_X)\n",
    "res_pred_negatives = model.fit(train_X, train_Y[:, 2], validation_split=0.2, epochs=20, class_weight = class_weight_negatives)\n",
    "pred_test_x_negatives = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_pred = res_pred.history['accuracy'][-1]\n",
    "test_acc_pred = res_pred.history['val_accuracy'][-1]\n",
    "\n",
    "acc_pos_pred = res_pred_pos.history['accuracy'][-1]\n",
    "test_acc_pos_pred = res_pred_pos.history['val_accuracy'][-1]\n",
    "\n",
    "acc_neg_pred = res_pred_negatives.history['accuracy'][-1]\n",
    "test_acc_neg_pred = res_pred_negatives.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rounding on starting_test\n",
    "## Output in probabilistic form, rounding the variables if p>=0.5 to 1, opposite to 0\n",
    "pred_test_X_round = np.round(pred_test_x, decimals=0)\n",
    "pred_test_X_ones_round = np.round(pred_test_x_ones, decimals=0)\n",
    "pred_test_X_negatives_round = np.round(pred_test_x_negatives, decimals=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starting the iteration for at least 40000 articles.\n",
    "## From there on the remaining ones will be predicted normally\n",
    "\n",
    "test_pred_Y = np.hstack((pred_test_X_round, pred_test_X_ones_round, pred_test_X_negatives_round))\n",
    "\n",
    "starting_df_Y = np.vstack((train_Y, test_pred_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting last_index and setting the first parameters for the iteration\n",
    "\n",
    "last_ind = starting_test.index[-1]\n",
    "iterat = 0\n",
    "df_Y_i = starting_df_Y\n",
    "starting_df_iterat = final_df.iloc[:last_ind+1, :]\n",
    "accuracy_l = []\n",
    "accuracy_ones_l = []\n",
    "accuracy_negatives_l = []\n",
    "validation_l = []\n",
    "validation_ones_l = []\n",
    "validation_negatives_l = []\n",
    "n = 0\n",
    "\n",
    "class_weight = {0 : 3.0,\n",
    "                1 : 1.0}\n",
    "class_weight_negatives = {0 : 1.,\n",
    "                          1 : 5.0}\n",
    "class_weight_positives = {0 : 1.,\n",
    "                          1 : 4.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emigi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df iterat initial shape : (2646, 26)\n",
      "Shape Train X : (1852, 100)\n",
      "Shape Test X : (794, 100)\n",
      "Shape Y : (1852, 3)\n",
      "Train on 1481 samples, validate on 371 samples\n",
      "Epoch 1/50\n",
      "1481/1481 [==============================] - 8s 5ms/step - loss: 1.1172 - accuracy: 0.3295 - val_loss: 1.2664 - val_accuracy: 0.5364\n",
      "Epoch 2/50\n",
      "1481/1481 [==============================] - 5s 4ms/step - loss: 1.1099 - accuracy: 0.3639 - val_loss: 1.1739 - val_accuracy: 0.5418\n",
      "Epoch 3/50\n",
      "1481/1481 [==============================] - 5s 4ms/step - loss: 1.1127 - accuracy: 0.3329 - val_loss: 1.2410 - val_accuracy: 0.5580\n",
      "Epoch 4/50\n",
      "1481/1481 [==============================] - 5s 4ms/step - loss: 1.1014 - accuracy: 0.3315 - val_loss: 1.3033 - val_accuracy: 0.5633\n",
      "Epoch 5/50\n",
      "1481/1481 [==============================] - 5s 4ms/step - loss: 1.0956 - accuracy: 0.3383 - val_loss: 1.2139 - val_accuracy: 0.5633\n",
      "Epoch 6/50\n",
      "1481/1481 [==============================] - 5s 4ms/step - loss: 1.0879 - accuracy: 0.3937 - val_loss: 1.1084 - val_accuracy: 0.5580\n",
      "Epoch 7/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.1002 - accuracy: 0.3714 - val_loss: 1.2003 - val_accuracy: 0.5633\n",
      "Epoch 8/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0757 - accuracy: 0.4193 - val_loss: 1.1220 - val_accuracy: 0.6550\n",
      "Epoch 9/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0536 - accuracy: 0.5017 - val_loss: 1.1542 - val_accuracy: 0.7763\n",
      "Epoch 10/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0570 - accuracy: 0.5165 - val_loss: 1.1403 - val_accuracy: 0.7898\n",
      "Epoch 11/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0399 - accuracy: 0.5409 - val_loss: 1.3975 - val_accuracy: 0.6900\n",
      "Epoch 12/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0481 - accuracy: 0.5179 - val_loss: 1.0458 - val_accuracy: 0.7358\n",
      "Epoch 13/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0378 - accuracy: 0.5490 - val_loss: 1.1318 - val_accuracy: 0.7925\n",
      "Epoch 14/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0269 - accuracy: 0.5469 - val_loss: 1.0691 - val_accuracy: 0.7709\n",
      "Epoch 15/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0328 - accuracy: 0.5584 - val_loss: 1.0129 - val_accuracy: 0.7655\n",
      "Epoch 16/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0267 - accuracy: 0.5496 - val_loss: 1.0731 - val_accuracy: 0.7871\n",
      "Epoch 17/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0194 - accuracy: 0.5530 - val_loss: 0.9781 - val_accuracy: 0.7925\n",
      "Epoch 18/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0195 - accuracy: 0.5564 - val_loss: 1.0201 - val_accuracy: 0.7763\n",
      "Epoch 19/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0278 - accuracy: 0.5334 - val_loss: 0.9850 - val_accuracy: 0.7089\n",
      "Epoch 20/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0258 - accuracy: 0.5368 - val_loss: 1.0091 - val_accuracy: 0.7951\n",
      "Epoch 21/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0126 - accuracy: 0.5523 - val_loss: 1.0018 - val_accuracy: 0.7116\n",
      "Epoch 22/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0088 - accuracy: 0.5510 - val_loss: 1.1280 - val_accuracy: 0.7520\n",
      "Epoch 23/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0130 - accuracy: 0.5564 - val_loss: 1.0457 - val_accuracy: 0.7763\n",
      "Epoch 24/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0082 - accuracy: 0.5510 - val_loss: 0.9759 - val_accuracy: 0.7493\n",
      "Epoch 25/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0109 - accuracy: 0.5267 - val_loss: 0.9991 - val_accuracy: 0.7709\n",
      "Epoch 26/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0100 - accuracy: 0.5510 - val_loss: 1.0225 - val_accuracy: 0.7925\n",
      "Epoch 27/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0086 - accuracy: 0.5490 - val_loss: 1.0010 - val_accuracy: 0.7358\n",
      "Epoch 28/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0107 - accuracy: 0.5361 - val_loss: 1.0319 - val_accuracy: 0.7844\n",
      "Epoch 29/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0054 - accuracy: 0.5463 - val_loss: 1.0445 - val_accuracy: 0.7978\n",
      "Epoch 30/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0053 - accuracy: 0.5449 - val_loss: 1.0310 - val_accuracy: 0.7790\n",
      "Epoch 31/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0043 - accuracy: 0.5422 - val_loss: 1.1079 - val_accuracy: 0.7412\n",
      "Epoch 32/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0037 - accuracy: 0.5557 - val_loss: 1.0183 - val_accuracy: 0.7601\n",
      "Epoch 33/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0089 - accuracy: 0.5159 - val_loss: 1.0976 - val_accuracy: 0.7763\n",
      "Epoch 34/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0016 - accuracy: 0.5490 - val_loss: 1.0228 - val_accuracy: 0.7574\n",
      "Epoch 35/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0055 - accuracy: 0.5415 - val_loss: 1.1088 - val_accuracy: 0.7709\n",
      "Epoch 36/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0023 - accuracy: 0.5463 - val_loss: 1.0742 - val_accuracy: 0.7736\n",
      "Epoch 37/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 0.9955 - accuracy: 0.5415 - val_loss: 0.9653 - val_accuracy: 0.7574\n",
      "Epoch 38/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0049 - accuracy: 0.5300 - val_loss: 1.0443 - val_accuracy: 0.7736\n",
      "Epoch 39/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0002 - accuracy: 0.5368 - val_loss: 1.0435 - val_accuracy: 0.7898\n",
      "Epoch 40/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0027 - accuracy: 0.5571 - val_loss: 0.9805 - val_accuracy: 0.7197\n",
      "Epoch 41/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0030 - accuracy: 0.5246 - val_loss: 0.9601 - val_accuracy: 0.7143\n",
      "Epoch 42/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0001 - accuracy: 0.5388 - val_loss: 0.9838 - val_accuracy: 0.7466\n",
      "Epoch 43/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 0.9963 - accuracy: 0.5402 - val_loss: 0.9861 - val_accuracy: 0.7439\n",
      "Epoch 44/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 0.9978 - accuracy: 0.5314 - val_loss: 1.0376 - val_accuracy: 0.7682\n",
      "Epoch 45/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 0.9940 - accuracy: 0.5550 - val_loss: 1.0598 - val_accuracy: 0.7736\n",
      "Epoch 46/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 0.9927 - accuracy: 0.5341 - val_loss: 1.0706 - val_accuracy: 0.7655\n",
      "Epoch 47/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 0.9910 - accuracy: 0.5463 - val_loss: 1.0234 - val_accuracy: 0.7709\n",
      "Epoch 48/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 0.9938 - accuracy: 0.5280 - val_loss: 1.0415 - val_accuracy: 0.7628\n",
      "Epoch 49/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 0.9949 - accuracy: 0.5422 - val_loss: 1.0444 - val_accuracy: 0.7520\n",
      "Epoch 50/50\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 0.9911 - accuracy: 0.5476 - val_loss: 1.1555 - val_accuracy: 0.7547\n",
      "Train on 1481 samples, validate on 371 samples\n",
      "Epoch 1/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.1137 - accuracy: 0.7144 - val_loss: 0.5682 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0506 - accuracy: 0.8501 - val_loss: 0.6187 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0505 - accuracy: 0.8501 - val_loss: 0.6265 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0457 - accuracy: 0.8501 - val_loss: 0.5694 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0506 - accuracy: 0.8501 - val_loss: 0.5733 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0462 - accuracy: 0.8501 - val_loss: 0.5867 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0485 - accuracy: 0.8501 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0397 - accuracy: 0.8501 - val_loss: 0.5674 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0456 - accuracy: 0.8501 - val_loss: 0.6083 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 1.0445 - accuracy: 0.8501 - val_loss: 0.5785 - val_accuracy: 1.0000\n",
      "Train on 1481 samples, validate on 371 samples\n",
      "Epoch 1/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 0.9081 - accuracy: 0.8994 - val_loss: 0.3389 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 0.9313 - accuracy: 0.8994 - val_loss: 0.4442 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 0.9111 - accuracy: 0.8994 - val_loss: 0.4781 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 0.9208 - accuracy: 0.8994 - val_loss: 0.4444 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 0.9231 - accuracy: 0.8994 - val_loss: 0.4447 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 0.9193 - accuracy: 0.8994 - val_loss: 0.4888 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 0.9113 - accuracy: 0.8994 - val_loss: 0.4794 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 0.9093 - accuracy: 0.8994 - val_loss: 0.4294 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 0.9085 - accuracy: 0.8994 - val_loss: 0.4843 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1481/1481 [==============================] - 6s 4ms/step - loss: 0.9056 - accuracy: 0.8994 - val_loss: 0.4756 - val_accuracy: 1.0000\n",
      "prevision shape : (794, 1)\n",
      "prevision shape ones : (794, 1)\n",
      "prevision shape negat : (794, 1)\n",
      "df iterat final shape : (2646, 26)\n",
      "final df Y shape : (2646, 3)\n",
      "df iterat initial shape : (3781, 26)\n",
      "Shape Train X : (2646, 100)\n",
      "Shape Test X : (1135, 100)\n",
      "Shape Y : (2646, 3)\n",
      "Train on 2116 samples, validate on 530 samples\n",
      "Epoch 1/50\n",
      "2116/2116 [==============================] - 41s 19ms/step - loss: 1.1263 - accuracy: 0.3488 - val_loss: 0.9728 - val_accuracy: 0.2094\n",
      "Epoch 2/50\n",
      "2116/2116 [==============================] - 39s 18ms/step - loss: 1.1186 - accuracy: 0.3578 - val_loss: 1.0358 - val_accuracy: 0.2057\n",
      "Epoch 3/50\n",
      "2116/2116 [==============================] - 37s 17ms/step - loss: 1.1047 - accuracy: 0.3677 - val_loss: 0.9213 - val_accuracy: 0.2925\n",
      "Epoch 4/50\n",
      "2116/2116 [==============================] - 37s 17ms/step - loss: 1.0708 - accuracy: 0.4490 - val_loss: 0.9049 - val_accuracy: 0.3981\n",
      "Epoch 5/50\n",
      "2116/2116 [==============================] - 37s 17ms/step - loss: 1.0629 - accuracy: 0.4792 - val_loss: 0.9019 - val_accuracy: 0.4321\n",
      "Epoch 6/50\n",
      "2116/2116 [==============================] - 37s 17ms/step - loss: 1.0268 - accuracy: 0.5581 - val_loss: 0.8723 - val_accuracy: 0.4981\n",
      "Epoch 7/50\n",
      "2116/2116 [==============================] - 37s 17ms/step - loss: 1.0208 - accuracy: 0.5515 - val_loss: 0.8671 - val_accuracy: 0.5226\n",
      "Epoch 8/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 1.0153 - accuracy: 0.5718 - val_loss: 0.8959 - val_accuracy: 0.5019\n",
      "Epoch 9/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9956 - accuracy: 0.6063 - val_loss: 0.8809 - val_accuracy: 0.5170\n",
      "Epoch 10/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9760 - accuracy: 0.6153 - val_loss: 0.8220 - val_accuracy: 0.5453\n",
      "Epoch 11/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9824 - accuracy: 0.6073 - val_loss: 0.8259 - val_accuracy: 0.5509\n",
      "Epoch 12/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9838 - accuracy: 0.6129 - val_loss: 0.7451 - val_accuracy: 0.6245\n",
      "Epoch 13/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9778 - accuracy: 0.6106 - val_loss: 0.8603 - val_accuracy: 0.5019\n",
      "Epoch 14/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9746 - accuracy: 0.6205 - val_loss: 0.8970 - val_accuracy: 0.4887\n",
      "Epoch 15/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9758 - accuracy: 0.6087 - val_loss: 0.8864 - val_accuracy: 0.5019\n",
      "Epoch 16/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9639 - accuracy: 0.6087 - val_loss: 0.8719 - val_accuracy: 0.5057\n",
      "Epoch 17/50\n",
      "2116/2116 [==============================] - 37s 17ms/step - loss: 0.9706 - accuracy: 0.6063 - val_loss: 0.7970 - val_accuracy: 0.5623\n",
      "Epoch 18/50\n",
      "2116/2116 [==============================] - 38s 18ms/step - loss: 0.9666 - accuracy: 0.6172 - val_loss: 0.8048 - val_accuracy: 0.5717\n",
      "Epoch 19/50\n",
      "2116/2116 [==============================] - 37s 17ms/step - loss: 0.9743 - accuracy: 0.5988 - val_loss: 0.8637 - val_accuracy: 0.4925\n",
      "Epoch 20/50\n",
      "2116/2116 [==============================] - 37s 17ms/step - loss: 0.9732 - accuracy: 0.6044 - val_loss: 0.7779 - val_accuracy: 0.5906\n",
      "Epoch 21/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9577 - accuracy: 0.6191 - val_loss: 0.8368 - val_accuracy: 0.5283\n",
      "Epoch 22/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9555 - accuracy: 0.6096 - val_loss: 0.8155 - val_accuracy: 0.5491\n",
      "Epoch 23/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9580 - accuracy: 0.5969 - val_loss: 0.8212 - val_accuracy: 0.5528\n",
      "Epoch 24/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9654 - accuracy: 0.6200 - val_loss: 0.8062 - val_accuracy: 0.5660\n",
      "Epoch 25/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9556 - accuracy: 0.6134 - val_loss: 0.7603 - val_accuracy: 0.5962\n",
      "Epoch 26/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9636 - accuracy: 0.6096 - val_loss: 0.8477 - val_accuracy: 0.5283\n",
      "Epoch 27/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9484 - accuracy: 0.6125 - val_loss: 0.7685 - val_accuracy: 0.5774\n",
      "Epoch 28/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9650 - accuracy: 0.6026 - val_loss: 0.8222 - val_accuracy: 0.5509\n",
      "Epoch 29/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9488 - accuracy: 0.6134 - val_loss: 0.7766 - val_accuracy: 0.5717\n",
      "Epoch 30/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9487 - accuracy: 0.6215 - val_loss: 0.8527 - val_accuracy: 0.5038\n",
      "Epoch 31/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9479 - accuracy: 0.6068 - val_loss: 0.7580 - val_accuracy: 0.5906\n",
      "Epoch 32/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9472 - accuracy: 0.6073 - val_loss: 0.7066 - val_accuracy: 0.6264\n",
      "Epoch 33/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9509 - accuracy: 0.6087 - val_loss: 0.7531 - val_accuracy: 0.6019\n",
      "Epoch 34/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9556 - accuracy: 0.6148 - val_loss: 0.8043 - val_accuracy: 0.5604\n",
      "Epoch 35/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9467 - accuracy: 0.6134 - val_loss: 0.7788 - val_accuracy: 0.5792\n",
      "Epoch 36/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9443 - accuracy: 0.6181 - val_loss: 0.7460 - val_accuracy: 0.6075\n",
      "Epoch 37/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9452 - accuracy: 0.6030 - val_loss: 0.7695 - val_accuracy: 0.5528\n",
      "Epoch 38/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9420 - accuracy: 0.6172 - val_loss: 0.7887 - val_accuracy: 0.5717\n",
      "Epoch 39/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9467 - accuracy: 0.6115 - val_loss: 0.8016 - val_accuracy: 0.5585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9484 - accuracy: 0.6096 - val_loss: 0.8196 - val_accuracy: 0.5208\n",
      "Epoch 41/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9395 - accuracy: 0.6082 - val_loss: 0.7905 - val_accuracy: 0.5679\n",
      "Epoch 42/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9404 - accuracy: 0.6144 - val_loss: 0.8162 - val_accuracy: 0.5189\n",
      "Epoch 43/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9431 - accuracy: 0.6106 - val_loss: 0.7815 - val_accuracy: 0.5585\n",
      "Epoch 44/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9535 - accuracy: 0.5988 - val_loss: 0.7775 - val_accuracy: 0.5642\n",
      "Epoch 45/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9518 - accuracy: 0.6026 - val_loss: 0.7572 - val_accuracy: 0.5849\n",
      "Epoch 46/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9454 - accuracy: 0.6125 - val_loss: 0.7336 - val_accuracy: 0.5943\n",
      "Epoch 47/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9415 - accuracy: 0.6125 - val_loss: 0.7400 - val_accuracy: 0.6038\n",
      "Epoch 48/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9363 - accuracy: 0.6148 - val_loss: 0.7344 - val_accuracy: 0.5925\n",
      "Epoch 49/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9359 - accuracy: 0.6158 - val_loss: 0.8365 - val_accuracy: 0.4868\n",
      "Epoch 50/50\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9445 - accuracy: 0.6167 - val_loss: 0.7839 - val_accuracy: 0.5604\n",
      "Train on 2116 samples, validate on 530 samples\n",
      "Epoch 1/10\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.9424 - accuracy: 0.8601 - val_loss: 0.3977 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "2116/2116 [==============================] - 35s 17ms/step - loss: 0.8913 - accuracy: 0.8951 - val_loss: 0.3418 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "2116/2116 [==============================] - 35s 17ms/step - loss: 0.8854 - accuracy: 0.8951 - val_loss: 0.4493 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "2116/2116 [==============================] - 35s 17ms/step - loss: 0.8835 - accuracy: 0.8951 - val_loss: 0.4260 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "2116/2116 [==============================] - 35s 17ms/step - loss: 0.8814 - accuracy: 0.8951 - val_loss: 0.4626 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "2116/2116 [==============================] - 35s 17ms/step - loss: 0.8828 - accuracy: 0.8951 - val_loss: 0.4699 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "2116/2116 [==============================] - 35s 17ms/step - loss: 0.8734 - accuracy: 0.8951 - val_loss: 0.3878 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.8749 - accuracy: 0.8951 - val_loss: 0.4124 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "2116/2116 [==============================] - 35s 17ms/step - loss: 0.8735 - accuracy: 0.8951 - val_loss: 0.4208 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2116/2116 [==============================] - 35s 17ms/step - loss: 0.8682 - accuracy: 0.8951 - val_loss: 0.3465 - val_accuracy: 1.0000\n",
      "Train on 2116 samples, validate on 530 samples\n",
      "Epoch 1/10\n",
      "2116/2116 [==============================] - 36s 17ms/step - loss: 0.7649 - accuracy: 0.9296 - val_loss: 0.3510 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "2116/2116 [==============================] - 35s 17ms/step - loss: 0.7640 - accuracy: 0.9296 - val_loss: 0.3091 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "2116/2116 [==============================] - 35s 17ms/step - loss: 0.7607 - accuracy: 0.9296 - val_loss: 0.3563 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "2116/2116 [==============================] - 35s 17ms/step - loss: 0.7496 - accuracy: 0.9296 - val_loss: 0.3572 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "2116/2116 [==============================] - 35s 17ms/step - loss: 0.7370 - accuracy: 0.9296 - val_loss: 0.2623 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "2116/2116 [==============================] - 35s 17ms/step - loss: 0.7203 - accuracy: 0.9296 - val_loss: 0.3122 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "2116/2116 [==============================] - 35s 17ms/step - loss: 0.6976 - accuracy: 0.9296 - val_loss: 0.3484 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "2116/2116 [==============================] - 35s 17ms/step - loss: 0.6817 - accuracy: 0.9296 - val_loss: 0.2802 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "2116/2116 [==============================] - 35s 17ms/step - loss: 0.6626 - accuracy: 0.9296 - val_loss: 0.3258 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2116/2116 [==============================] - 35s 17ms/step - loss: 0.6484 - accuracy: 0.9296 - val_loss: 0.2531 - val_accuracy: 1.0000\n",
      "prevision shape : (1135, 1)\n",
      "prevision shape ones : (1135, 1)\n",
      "prevision shape negat : (1135, 1)\n",
      "df iterat final shape : (3781, 26)\n",
      "final df Y shape : (3781, 3)\n",
      "df iterat initial shape : (5402, 26)\n",
      "Shape Train X : (3781, 100)\n",
      "Shape Test X : (1621, 100)\n",
      "Shape Y : (3781, 3)\n",
      "Train on 3024 samples, validate on 757 samples\n",
      "Epoch 1/50\n",
      "3024/3024 [==============================] - 51s 17ms/step - loss: 1.1363 - accuracy: 0.3922 - val_loss: 1.4678 - val_accuracy: 0.8798\n",
      "Epoch 2/50\n",
      "3024/3024 [==============================] - 49s 16ms/step - loss: 1.1118 - accuracy: 0.4137 - val_loss: 1.3162 - val_accuracy: 0.8573\n",
      "Epoch 3/50\n",
      "3024/3024 [==============================] - 49s 16ms/step - loss: 1.0986 - accuracy: 0.4306 - val_loss: 1.4886 - val_accuracy: 0.8217\n",
      "Epoch 4/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 1.0671 - accuracy: 0.4888 - val_loss: 1.1545 - val_accuracy: 0.8613\n",
      "Epoch 5/50\n",
      "3024/3024 [==============================] - 49s 16ms/step - loss: 1.0411 - accuracy: 0.5443 - val_loss: 1.2543 - val_accuracy: 0.8481\n",
      "Epoch 6/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 1.0330 - accuracy: 0.5456 - val_loss: 1.0862 - val_accuracy: 0.8745\n",
      "Epoch 7/50\n",
      "3024/3024 [==============================] - 49s 16ms/step - loss: 1.0250 - accuracy: 0.5605 - val_loss: 1.5749 - val_accuracy: 0.7239\n",
      "Epoch 8/50\n",
      "3024/3024 [==============================] - 49s 16ms/step - loss: 1.0187 - accuracy: 0.5618 - val_loss: 1.2069 - val_accuracy: 0.8375\n",
      "Epoch 9/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 1.0069 - accuracy: 0.5797 - val_loss: 1.1568 - val_accuracy: 0.8481\n",
      "Epoch 10/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 1.0081 - accuracy: 0.5929 - val_loss: 1.1724 - val_accuracy: 0.8402\n",
      "Epoch 11/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9999 - accuracy: 0.5714 - val_loss: 1.3089 - val_accuracy: 0.7926\n",
      "Epoch 12/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 1.0026 - accuracy: 0.5886 - val_loss: 1.1631 - val_accuracy: 0.8375\n",
      "Epoch 13/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9977 - accuracy: 0.5906 - val_loss: 1.1038 - val_accuracy: 0.8547\n",
      "Epoch 14/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9935 - accuracy: 0.5830 - val_loss: 1.1837 - val_accuracy: 0.8349\n",
      "Epoch 15/50\n",
      "3024/3024 [==============================] - 49s 16ms/step - loss: 0.9888 - accuracy: 0.5989 - val_loss: 1.1730 - val_accuracy: 0.8362\n",
      "Epoch 16/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9886 - accuracy: 0.5909 - val_loss: 1.0252 - val_accuracy: 0.8851\n",
      "Epoch 17/50\n",
      "3024/3024 [==============================] - 49s 16ms/step - loss: 0.9878 - accuracy: 0.5761 - val_loss: 1.1054 - val_accuracy: 0.8877\n",
      "Epoch 18/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9904 - accuracy: 0.5734 - val_loss: 1.3645 - val_accuracy: 0.7834\n",
      "Epoch 19/50\n",
      "3024/3024 [==============================] - 49s 16ms/step - loss: 0.9856 - accuracy: 0.5823 - val_loss: 1.1805 - val_accuracy: 0.8520\n",
      "Epoch 20/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9859 - accuracy: 0.5853 - val_loss: 1.3007 - val_accuracy: 0.8388\n",
      "Epoch 21/50\n",
      "3024/3024 [==============================] - 50s 17ms/step - loss: 0.9805 - accuracy: 0.5847 - val_loss: 1.1680 - val_accuracy: 0.8322\n",
      "Epoch 22/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9827 - accuracy: 0.5840 - val_loss: 1.3298 - val_accuracy: 0.8190\n",
      "Epoch 23/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9778 - accuracy: 0.5883 - val_loss: 1.2377 - val_accuracy: 0.8243\n",
      "Epoch 24/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9766 - accuracy: 0.5866 - val_loss: 1.2308 - val_accuracy: 0.8494\n",
      "Epoch 25/50\n",
      "3024/3024 [==============================] - 49s 16ms/step - loss: 0.9814 - accuracy: 0.5866 - val_loss: 1.2339 - val_accuracy: 0.8283\n",
      "Epoch 26/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9815 - accuracy: 0.5942 - val_loss: 1.2158 - val_accuracy: 0.8666\n",
      "Epoch 27/50\n",
      "3024/3024 [==============================] - 49s 16ms/step - loss: 0.9719 - accuracy: 0.5807 - val_loss: 1.0775 - val_accuracy: 0.8639\n",
      "Epoch 28/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9792 - accuracy: 0.5767 - val_loss: 1.1921 - val_accuracy: 0.8362\n",
      "Epoch 29/50\n",
      "3024/3024 [==============================] - 49s 16ms/step - loss: 0.9762 - accuracy: 0.5777 - val_loss: 1.2553 - val_accuracy: 0.8362\n",
      "Epoch 30/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9817 - accuracy: 0.5827 - val_loss: 1.0309 - val_accuracy: 0.8560\n",
      "Epoch 31/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9755 - accuracy: 0.5764 - val_loss: 1.2542 - val_accuracy: 0.8481\n",
      "Epoch 32/50\n",
      "3024/3024 [==============================] - 49s 16ms/step - loss: 0.9708 - accuracy: 0.5827 - val_loss: 1.1891 - val_accuracy: 0.8560\n",
      "Epoch 33/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9711 - accuracy: 0.5952 - val_loss: 1.1054 - val_accuracy: 0.8587\n",
      "Epoch 34/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9762 - accuracy: 0.5850 - val_loss: 1.1148 - val_accuracy: 0.8283\n",
      "Epoch 35/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9769 - accuracy: 0.5837 - val_loss: 1.2814 - val_accuracy: 0.8322\n",
      "Epoch 36/50\n",
      "3024/3024 [==============================] - 49s 16ms/step - loss: 0.9702 - accuracy: 0.5804 - val_loss: 1.1871 - val_accuracy: 0.8507\n",
      "Epoch 37/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9637 - accuracy: 0.5999 - val_loss: 1.0563 - val_accuracy: 0.8534\n",
      "Epoch 38/50\n",
      "3024/3024 [==============================] - 50s 17ms/step - loss: 0.9697 - accuracy: 0.5863 - val_loss: 1.2174 - val_accuracy: 0.8164\n",
      "Epoch 39/50\n",
      "3024/3024 [==============================] - 49s 16ms/step - loss: 0.9692 - accuracy: 0.6005 - val_loss: 1.1354 - val_accuracy: 0.8600\n",
      "Epoch 40/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9661 - accuracy: 0.5870 - val_loss: 1.5019 - val_accuracy: 0.7622\n",
      "Epoch 41/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9673 - accuracy: 0.5817 - val_loss: 1.2556 - val_accuracy: 0.8098\n",
      "Epoch 42/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9687 - accuracy: 0.5896 - val_loss: 1.0447 - val_accuracy: 0.8639\n",
      "Epoch 43/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9647 - accuracy: 0.5833 - val_loss: 1.0897 - val_accuracy: 0.8600\n",
      "Epoch 44/50\n",
      "3024/3024 [==============================] - 49s 16ms/step - loss: 0.9655 - accuracy: 0.5830 - val_loss: 1.1608 - val_accuracy: 0.8388\n",
      "Epoch 45/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9622 - accuracy: 0.5979 - val_loss: 1.0428 - val_accuracy: 0.8732\n",
      "Epoch 46/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9659 - accuracy: 0.5737 - val_loss: 1.2983 - val_accuracy: 0.7979\n",
      "Epoch 47/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9679 - accuracy: 0.5995 - val_loss: 1.2677 - val_accuracy: 0.8151\n",
      "Epoch 48/50\n",
      "3024/3024 [==============================] - 49s 16ms/step - loss: 0.9621 - accuracy: 0.5843 - val_loss: 1.3481 - val_accuracy: 0.7768\n",
      "Epoch 49/50\n",
      "3024/3024 [==============================] - 49s 16ms/step - loss: 0.9620 - accuracy: 0.5985 - val_loss: 1.1600 - val_accuracy: 0.8190\n",
      "Epoch 50/50\n",
      "3024/3024 [==============================] - 50s 16ms/step - loss: 0.9597 - accuracy: 0.5890 - val_loss: 1.1961 - val_accuracy: 0.8309\n",
      "Train on 3024 samples, validate on 757 samples\n",
      "Epoch 1/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.7691 - accuracy: 0.8998 - val_loss: 0.3540 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.7295 - accuracy: 0.9266 - val_loss: 0.2966 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.7261 - accuracy: 0.9266 - val_loss: 0.2207 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.7192 - accuracy: 0.9266 - val_loss: 0.2310 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.7162 - accuracy: 0.9266 - val_loss: 0.2630 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.7046 - accuracy: 0.9266 - val_loss: 0.2725 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.6921 - accuracy: 0.9266 - val_loss: 0.3217 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.6725 - accuracy: 0.9266 - val_loss: 0.2211 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.6602 - accuracy: 0.9266 - val_loss: 0.1298 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.6446 - accuracy: 0.9266 - val_loss: 0.2371 - val_accuracy: 1.0000\n",
      "Train on 3024 samples, validate on 757 samples\n",
      "Epoch 1/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.6350 - accuracy: 0.9507 - val_loss: 0.1977 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.5989 - accuracy: 0.9507 - val_loss: 0.2623 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.5946 - accuracy: 0.9507 - val_loss: 0.1584 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.5672 - accuracy: 0.9507 - val_loss: 0.1598 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.5430 - accuracy: 0.9507 - val_loss: 0.1461 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.5335 - accuracy: 0.9507 - val_loss: 0.2300 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.5245 - accuracy: 0.9507 - val_loss: 0.2237 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.5111 - accuracy: 0.9507 - val_loss: 0.1963 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.5073 - accuracy: 0.9501 - val_loss: 0.1754 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3024/3024 [==============================] - 48s 16ms/step - loss: 0.5018 - accuracy: 0.9507 - val_loss: 0.1378 - val_accuracy: 1.0000\n",
      "prevision shape : (1621, 1)\n",
      "prevision shape ones : (1621, 1)\n",
      "prevision shape negat : (1621, 1)\n",
      "df iterat final shape : (5402, 26)\n",
      "final df Y shape : (5402, 3)\n",
      "df iterat initial shape : (7718, 26)\n",
      "Shape Train X : (5402, 100)\n",
      "Shape Test X : (2316, 100)\n",
      "Shape Y : (5402, 3)\n",
      "Train on 4321 samples, validate on 1081 samples\n",
      "Epoch 1/50\n",
      "4321/4321 [==============================] - 71s 16ms/step - loss: 1.1072 - accuracy: 0.5469 - val_loss: 0.7195 - val_accuracy: 0.9639\n",
      "Epoch 2/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 1.0874 - accuracy: 0.5550 - val_loss: 0.8481 - val_accuracy: 0.9639\n",
      "Epoch 3/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 1.0746 - accuracy: 0.5547 - val_loss: 0.6024 - val_accuracy: 0.9639\n",
      "Epoch 4/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 1.0411 - accuracy: 0.5561 - val_loss: 1.1777 - val_accuracy: 0.9408\n",
      "Epoch 5/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 1.0189 - accuracy: 0.5702 - val_loss: 1.0421 - val_accuracy: 0.9195\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4321/4321 [==============================] - 69s 16ms/step - loss: 1.0006 - accuracy: 0.5850 - val_loss: 0.7347 - val_accuracy: 0.9454\n",
      "Epoch 7/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9852 - accuracy: 0.6017 - val_loss: 0.6045 - val_accuracy: 0.9741\n",
      "Epoch 8/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9929 - accuracy: 0.5985 - val_loss: 0.9190 - val_accuracy: 0.9500\n",
      "Epoch 9/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9899 - accuracy: 0.6087 - val_loss: 0.5579 - val_accuracy: 0.9426\n",
      "Epoch 10/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9786 - accuracy: 0.6098 - val_loss: 0.6289 - val_accuracy: 0.9380\n",
      "Epoch 11/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9795 - accuracy: 0.6061 - val_loss: 0.7502 - val_accuracy: 0.9500\n",
      "Epoch 12/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9696 - accuracy: 0.6061 - val_loss: 0.6061 - val_accuracy: 0.9537\n",
      "Epoch 13/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9716 - accuracy: 0.6089 - val_loss: 0.6214 - val_accuracy: 0.9602\n",
      "Epoch 14/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9714 - accuracy: 0.6008 - val_loss: 0.7974 - val_accuracy: 0.9426\n",
      "Epoch 15/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9680 - accuracy: 0.5992 - val_loss: 0.8359 - val_accuracy: 0.9251\n",
      "Epoch 16/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9650 - accuracy: 0.6098 - val_loss: 0.7942 - val_accuracy: 0.9463\n",
      "Epoch 17/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9595 - accuracy: 0.6075 - val_loss: 0.6575 - val_accuracy: 0.9547\n",
      "Epoch 18/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9586 - accuracy: 0.5999 - val_loss: 0.9124 - val_accuracy: 0.9223\n",
      "Epoch 19/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9613 - accuracy: 0.6070 - val_loss: 0.8924 - val_accuracy: 0.9380\n",
      "Epoch 20/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9579 - accuracy: 0.6019 - val_loss: 0.7965 - val_accuracy: 0.9315\n",
      "Epoch 21/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9603 - accuracy: 0.6019 - val_loss: 0.7046 - val_accuracy: 0.9426\n",
      "Epoch 22/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9540 - accuracy: 0.6082 - val_loss: 0.8303 - val_accuracy: 0.9223\n",
      "Epoch 23/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9572 - accuracy: 0.6043 - val_loss: 0.7021 - val_accuracy: 0.9426\n",
      "Epoch 24/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9497 - accuracy: 0.6103 - val_loss: 0.7851 - val_accuracy: 0.9315\n",
      "Epoch 25/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9543 - accuracy: 0.6082 - val_loss: 0.7980 - val_accuracy: 0.9241\n",
      "Epoch 26/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9509 - accuracy: 0.6036 - val_loss: 0.7470 - val_accuracy: 0.9426\n",
      "Epoch 27/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9505 - accuracy: 0.6006 - val_loss: 0.7279 - val_accuracy: 0.9278\n",
      "Epoch 28/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9496 - accuracy: 0.6010 - val_loss: 0.7518 - val_accuracy: 0.9482\n",
      "Epoch 29/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9485 - accuracy: 0.6040 - val_loss: 0.7247 - val_accuracy: 0.9426\n",
      "Epoch 30/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9431 - accuracy: 0.6091 - val_loss: 0.7172 - val_accuracy: 0.9352\n",
      "Epoch 31/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9470 - accuracy: 0.6070 - val_loss: 0.7125 - val_accuracy: 0.9426\n",
      "Epoch 32/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9452 - accuracy: 0.6080 - val_loss: 0.7260 - val_accuracy: 0.9399\n",
      "Epoch 33/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9448 - accuracy: 0.6093 - val_loss: 0.6375 - val_accuracy: 0.9593\n",
      "Epoch 34/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9463 - accuracy: 0.6040 - val_loss: 0.7777 - val_accuracy: 0.9482\n",
      "Epoch 35/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9458 - accuracy: 0.6082 - val_loss: 0.7310 - val_accuracy: 0.9454\n",
      "Epoch 36/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9451 - accuracy: 0.6084 - val_loss: 0.7224 - val_accuracy: 0.9334\n",
      "Epoch 37/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9449 - accuracy: 0.6059 - val_loss: 0.7440 - val_accuracy: 0.9186\n",
      "Epoch 38/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9454 - accuracy: 0.6045 - val_loss: 0.7098 - val_accuracy: 0.9426\n",
      "Epoch 39/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9393 - accuracy: 0.6091 - val_loss: 0.6937 - val_accuracy: 0.9334\n",
      "Epoch 40/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9418 - accuracy: 0.6124 - val_loss: 0.7899 - val_accuracy: 0.9278\n",
      "Epoch 41/50\n",
      "4321/4321 [==============================] - 70s 16ms/step - loss: 0.9419 - accuracy: 0.6084 - val_loss: 0.6537 - val_accuracy: 0.9482\n",
      "Epoch 42/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9410 - accuracy: 0.6096 - val_loss: 0.7361 - val_accuracy: 0.9334\n",
      "Epoch 43/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9395 - accuracy: 0.6112 - val_loss: 0.6950 - val_accuracy: 0.9334\n",
      "Epoch 44/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9391 - accuracy: 0.6112 - val_loss: 0.6679 - val_accuracy: 0.9454\n",
      "Epoch 45/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9421 - accuracy: 0.6029 - val_loss: 0.7100 - val_accuracy: 0.9334\n",
      "Epoch 46/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9391 - accuracy: 0.6117 - val_loss: 0.6072 - val_accuracy: 0.9454\n",
      "Epoch 47/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9398 - accuracy: 0.6112 - val_loss: 0.7955 - val_accuracy: 0.9426\n",
      "Epoch 48/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9366 - accuracy: 0.6068 - val_loss: 0.8089 - val_accuracy: 0.9306\n",
      "Epoch 49/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9369 - accuracy: 0.6124 - val_loss: 0.7267 - val_accuracy: 0.9362\n",
      "Epoch 50/50\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.9375 - accuracy: 0.6137 - val_loss: 0.7291 - val_accuracy: 0.9426\n",
      "Train on 4321 samples, validate on 1081 samples\n",
      "Epoch 1/10\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.6042 - accuracy: 0.9359 - val_loss: 0.2360 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "4321/4321 [==============================] - 68s 16ms/step - loss: 0.5678 - accuracy: 0.9486 - val_loss: 0.2192 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.5356 - accuracy: 0.9486 - val_loss: 0.1580 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "4321/4321 [==============================] - 68s 16ms/step - loss: 0.5250 - accuracy: 0.9486 - val_loss: 0.1567 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.4978 - accuracy: 0.9486 - val_loss: 0.1273 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "4321/4321 [==============================] - 68s 16ms/step - loss: 0.4972 - accuracy: 0.9486 - val_loss: 0.1391 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.4805 - accuracy: 0.9486 - val_loss: 0.1237 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.4746 - accuracy: 0.9486 - val_loss: 0.1854 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.4698 - accuracy: 0.9486 - val_loss: 0.1715 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.4687 - accuracy: 0.9486 - val_loss: 0.1743 - val_accuracy: 1.0000\n",
      "Train on 4321 samples, validate on 1081 samples\n",
      "Epoch 1/10\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.5024 - accuracy: 0.9655 - val_loss: 0.1446 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.4573 - accuracy: 0.9655 - val_loss: 0.1602 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.4325 - accuracy: 0.9655 - val_loss: 0.1090 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.4254 - accuracy: 0.9655 - val_loss: 0.1364 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.4118 - accuracy: 0.9655 - val_loss: 0.1085 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.4035 - accuracy: 0.9655 - val_loss: 0.1531 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.4018 - accuracy: 0.9655 - val_loss: 0.1524 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.3869 - accuracy: 0.9655 - val_loss: 0.1007 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.3842 - accuracy: 0.9655 - val_loss: 0.1020 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "4321/4321 [==============================] - 69s 16ms/step - loss: 0.3711 - accuracy: 0.9655 - val_loss: 0.1434 - val_accuracy: 1.0000\n",
      "prevision shape : (2316, 1)\n",
      "prevision shape ones : (2316, 1)\n",
      "prevision shape negat : (2316, 1)\n",
      "df iterat final shape : (7718, 26)\n",
      "final df Y shape : (7718, 3)\n",
      "df iterat initial shape : (11026, 26)\n",
      "Shape Train X : (7718, 100)\n",
      "Shape Test X : (3308, 100)\n",
      "Shape Y : (7718, 3)\n",
      "Train on 6174 samples, validate on 1544 samples\n",
      "Epoch 1/50\n",
      "6174/6174 [==============================] - 98s 16ms/step - loss: 0.9720 - accuracy: 0.6751 - val_loss: 0.5543 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.9438 - accuracy: 0.6822 - val_loss: 0.3485 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "6174/6174 [==============================] - 97s 16ms/step - loss: 0.9237 - accuracy: 0.6816 - val_loss: 0.5399 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.9037 - accuracy: 0.6824 - val_loss: 0.5133 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8853 - accuracy: 0.6827 - val_loss: 0.4494 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8661 - accuracy: 0.6824 - val_loss: 0.3647 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8624 - accuracy: 0.6837 - val_loss: 0.3224 - val_accuracy: 0.9981\n",
      "Epoch 8/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8559 - accuracy: 0.6842 - val_loss: 0.4582 - val_accuracy: 0.9955\n",
      "Epoch 9/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8556 - accuracy: 0.6851 - val_loss: 0.4565 - val_accuracy: 0.9935\n",
      "Epoch 10/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8561 - accuracy: 0.6872 - val_loss: 0.3747 - val_accuracy: 0.9955\n",
      "Epoch 11/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8513 - accuracy: 0.6876 - val_loss: 0.4817 - val_accuracy: 0.9935\n",
      "Epoch 12/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8447 - accuracy: 0.6882 - val_loss: 0.3842 - val_accuracy: 0.9935\n",
      "Epoch 13/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8427 - accuracy: 0.6882 - val_loss: 0.3581 - val_accuracy: 0.9916\n",
      "Epoch 14/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8421 - accuracy: 0.6895 - val_loss: 0.3613 - val_accuracy: 0.9935\n",
      "Epoch 15/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8402 - accuracy: 0.6879 - val_loss: 0.4094 - val_accuracy: 0.9916\n",
      "Epoch 16/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8434 - accuracy: 0.6908 - val_loss: 0.3559 - val_accuracy: 0.9916\n",
      "Epoch 17/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8413 - accuracy: 0.6902 - val_loss: 0.4347 - val_accuracy: 0.9896\n",
      "Epoch 18/50\n",
      "6174/6174 [==============================] - 97s 16ms/step - loss: 0.8384 - accuracy: 0.6903 - val_loss: 0.3235 - val_accuracy: 0.9896\n",
      "Epoch 19/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8355 - accuracy: 0.6908 - val_loss: 0.4316 - val_accuracy: 0.9896\n",
      "Epoch 20/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8333 - accuracy: 0.6911 - val_loss: 0.3996 - val_accuracy: 0.9896\n",
      "Epoch 21/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8321 - accuracy: 0.6926 - val_loss: 0.4057 - val_accuracy: 0.9896\n",
      "Epoch 22/50\n",
      "6174/6174 [==============================] - 97s 16ms/step - loss: 0.8312 - accuracy: 0.6916 - val_loss: 0.4074 - val_accuracy: 0.9851\n",
      "Epoch 23/50\n",
      "6174/6174 [==============================] - 97s 16ms/step - loss: 0.8301 - accuracy: 0.6929 - val_loss: 0.3736 - val_accuracy: 0.9870\n",
      "Epoch 24/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8296 - accuracy: 0.6914 - val_loss: 0.4005 - val_accuracy: 0.9870\n",
      "Epoch 25/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8269 - accuracy: 0.6924 - val_loss: 0.3216 - val_accuracy: 0.9916\n",
      "Epoch 26/50\n",
      "6174/6174 [==============================] - 97s 16ms/step - loss: 0.8283 - accuracy: 0.6918 - val_loss: 0.3859 - val_accuracy: 0.9870\n",
      "Epoch 27/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8263 - accuracy: 0.6924 - val_loss: 0.4552 - val_accuracy: 0.9870\n",
      "Epoch 28/50\n",
      "6174/6174 [==============================] - 97s 16ms/step - loss: 0.8273 - accuracy: 0.6910 - val_loss: 0.3980 - val_accuracy: 0.9870\n",
      "Epoch 29/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8203 - accuracy: 0.6921 - val_loss: 0.3721 - val_accuracy: 0.9916\n",
      "Epoch 30/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8280 - accuracy: 0.6910 - val_loss: 0.4245 - val_accuracy: 0.9870\n",
      "Epoch 31/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8262 - accuracy: 0.6923 - val_loss: 0.4693 - val_accuracy: 0.9870\n",
      "Epoch 32/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8223 - accuracy: 0.6913 - val_loss: 0.3605 - val_accuracy: 0.9870\n",
      "Epoch 33/50\n",
      "6174/6174 [==============================] - 97s 16ms/step - loss: 0.8211 - accuracy: 0.6923 - val_loss: 0.3740 - val_accuracy: 0.9870\n",
      "Epoch 34/50\n",
      "6174/6174 [==============================] - 97s 16ms/step - loss: 0.8212 - accuracy: 0.6923 - val_loss: 0.4002 - val_accuracy: 0.9870\n",
      "Epoch 35/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8235 - accuracy: 0.6923 - val_loss: 0.3861 - val_accuracy: 0.9896\n",
      "Epoch 36/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8215 - accuracy: 0.6923 - val_loss: 0.3953 - val_accuracy: 0.9870\n",
      "Epoch 37/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8240 - accuracy: 0.6926 - val_loss: 0.4096 - val_accuracy: 0.9870\n",
      "Epoch 38/50\n",
      "6174/6174 [==============================] - 97s 16ms/step - loss: 0.8248 - accuracy: 0.6921 - val_loss: 0.4047 - val_accuracy: 0.9845\n",
      "Epoch 39/50\n",
      "6174/6174 [==============================] - 97s 16ms/step - loss: 0.8260 - accuracy: 0.6906 - val_loss: 0.4163 - val_accuracy: 0.9870\n",
      "Epoch 40/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8204 - accuracy: 0.6924 - val_loss: 0.3841 - val_accuracy: 0.9870\n",
      "Epoch 41/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8247 - accuracy: 0.6923 - val_loss: 0.4365 - val_accuracy: 0.9870\n",
      "Epoch 42/50\n",
      "6174/6174 [==============================] - 97s 16ms/step - loss: 0.8216 - accuracy: 0.6923 - val_loss: 0.3567 - val_accuracy: 0.9870\n",
      "Epoch 43/50\n",
      "6174/6174 [==============================] - 97s 16ms/step - loss: 0.8216 - accuracy: 0.6906 - val_loss: 0.4401 - val_accuracy: 0.9870\n",
      "Epoch 44/50\n",
      "6174/6174 [==============================] - 97s 16ms/step - loss: 0.8219 - accuracy: 0.6913 - val_loss: 0.4300 - val_accuracy: 0.9870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8176 - accuracy: 0.6918 - val_loss: 0.3804 - val_accuracy: 0.9870\n",
      "Epoch 46/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8192 - accuracy: 0.6919 - val_loss: 0.4213 - val_accuracy: 0.9870\n",
      "Epoch 47/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8196 - accuracy: 0.6923 - val_loss: 0.3715 - val_accuracy: 0.9870\n",
      "Epoch 48/50\n",
      "6174/6174 [==============================] - 97s 16ms/step - loss: 0.8164 - accuracy: 0.6921 - val_loss: 0.3219 - val_accuracy: 0.9870\n",
      "Epoch 49/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8219 - accuracy: 0.6913 - val_loss: 0.4201 - val_accuracy: 0.9870\n",
      "Epoch 50/50\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.8159 - accuracy: 0.6921 - val_loss: 0.4027 - val_accuracy: 0.9870\n",
      "Train on 6174 samples, validate on 1544 samples\n",
      "Epoch 1/10\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.4655 - accuracy: 0.9571 - val_loss: 0.1350 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "6174/6174 [==============================] - 96s 16ms/step - loss: 0.4290 - accuracy: 0.9640 - val_loss: 0.1241 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "6174/6174 [==============================] - 96s 15ms/step - loss: 0.4084 - accuracy: 0.9640 - val_loss: 0.1106 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "6174/6174 [==============================] - 96s 15ms/step - loss: 0.3999 - accuracy: 0.9640 - val_loss: 0.0975 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "6174/6174 [==============================] - 96s 15ms/step - loss: 0.3850 - accuracy: 0.9640 - val_loss: 0.0935 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "6174/6174 [==============================] - 95s 15ms/step - loss: 0.3740 - accuracy: 0.9640 - val_loss: 0.1234 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "6174/6174 [==============================] - 96s 15ms/step - loss: 0.3754 - accuracy: 0.9640 - val_loss: 0.0891 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "6174/6174 [==============================] - 96s 15ms/step - loss: 0.3693 - accuracy: 0.9640 - val_loss: 0.1052 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "6174/6174 [==============================] - 96s 15ms/step - loss: 0.3605 - accuracy: 0.9640 - val_loss: 0.1145 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "6174/6174 [==============================] - 96s 15ms/step - loss: 0.3630 - accuracy: 0.9640 - val_loss: 0.1103 - val_accuracy: 1.0000\n",
      "Train on 6174 samples, validate on 1544 samples\n",
      "Epoch 1/10\n",
      "6174/6174 [==============================] - 96s 15ms/step - loss: 0.3775 - accuracy: 0.9759 - val_loss: 0.1033 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "6174/6174 [==============================] - 95s 15ms/step - loss: 0.3499 - accuracy: 0.9759 - val_loss: 0.0916 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "6174/6174 [==============================] - 96s 15ms/step - loss: 0.3371 - accuracy: 0.9759 - val_loss: 0.0891 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "6174/6174 [==============================] - 95s 15ms/step - loss: 0.3270 - accuracy: 0.9759 - val_loss: 0.0814 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "6174/6174 [==============================] - 96s 15ms/step - loss: 0.3222 - accuracy: 0.9759 - val_loss: 0.0616 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "6174/6174 [==============================] - 95s 15ms/step - loss: 0.3145 - accuracy: 0.9759 - val_loss: 0.0676 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "6174/6174 [==============================] - 95s 15ms/step - loss: 0.3073 - accuracy: 0.9759 - val_loss: 0.0416 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "6174/6174 [==============================] - 95s 15ms/step - loss: 0.3066 - accuracy: 0.9759 - val_loss: 0.0791 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "6174/6174 [==============================] - 96s 15ms/step - loss: 0.2970 - accuracy: 0.9759 - val_loss: 0.0616 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "6174/6174 [==============================] - 96s 15ms/step - loss: 0.2925 - accuracy: 0.9759 - val_loss: 0.0700 - val_accuracy: 1.0000\n",
      "prevision shape : (3308, 1)\n",
      "prevision shape ones : (3308, 1)\n",
      "prevision shape negat : (3308, 1)\n",
      "df iterat final shape : (11026, 26)\n",
      "final df Y shape : (11026, 3)\n",
      "df iterat initial shape : (15752, 26)\n",
      "Shape Train X : (11026, 100)\n",
      "Shape Test X : (4726, 100)\n",
      "Shape Y : (11026, 3)\n",
      "Train on 8820 samples, validate on 2206 samples\n",
      "Epoch 1/50\n",
      "8820/8820 [==============================] - 140s 16ms/step - loss: 0.7996 - accuracy: 0.7704 - val_loss: 0.3433 - val_accuracy: 0.9941\n",
      "Epoch 2/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.7613 - accuracy: 0.7753 - val_loss: 0.3462 - val_accuracy: 0.9982\n",
      "Epoch 3/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.7280 - accuracy: 0.7769 - val_loss: 0.2686 - val_accuracy: 0.9982\n",
      "Epoch 4/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.7075 - accuracy: 0.7770 - val_loss: 0.2874 - val_accuracy: 0.9973\n",
      "Epoch 5/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6901 - accuracy: 0.7761 - val_loss: 0.2007 - val_accuracy: 0.9968\n",
      "Epoch 6/50\n",
      "8820/8820 [==============================] - 139s 16ms/step - loss: 0.6772 - accuracy: 0.7764 - val_loss: 0.1208 - val_accuracy: 0.9977\n",
      "Epoch 7/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6719 - accuracy: 0.7776 - val_loss: 0.0966 - val_accuracy: 0.9977\n",
      "Epoch 8/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6673 - accuracy: 0.7776 - val_loss: 0.0769 - val_accuracy: 0.9977\n",
      "Epoch 9/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6676 - accuracy: 0.7771 - val_loss: 0.0986 - val_accuracy: 0.9964\n",
      "Epoch 10/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6578 - accuracy: 0.7772 - val_loss: 0.1147 - val_accuracy: 0.9982\n",
      "Epoch 11/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6562 - accuracy: 0.7771 - val_loss: 0.1029 - val_accuracy: 0.9982\n",
      "Epoch 12/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6511 - accuracy: 0.7780 - val_loss: 0.0764 - val_accuracy: 0.9986\n",
      "Epoch 13/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6519 - accuracy: 0.7770 - val_loss: 0.0932 - val_accuracy: 0.9982\n",
      "Epoch 14/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6475 - accuracy: 0.7786 - val_loss: 0.0609 - val_accuracy: 0.9982\n",
      "Epoch 15/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6488 - accuracy: 0.7766 - val_loss: 0.0914 - val_accuracy: 0.9973\n",
      "Epoch 16/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6470 - accuracy: 0.7772 - val_loss: 0.0864 - val_accuracy: 0.9964\n",
      "Epoch 17/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6451 - accuracy: 0.7776 - val_loss: 0.0789 - val_accuracy: 0.9937\n",
      "Epoch 18/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6451 - accuracy: 0.7781 - val_loss: 0.0883 - val_accuracy: 0.9973\n",
      "Epoch 19/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6455 - accuracy: 0.7777 - val_loss: 0.0749 - val_accuracy: 0.9982\n",
      "Epoch 20/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6427 - accuracy: 0.7766 - val_loss: 0.1056 - val_accuracy: 0.9982\n",
      "Epoch 21/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6419 - accuracy: 0.7770 - val_loss: 0.0776 - val_accuracy: 0.9973\n",
      "Epoch 22/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6411 - accuracy: 0.7765 - val_loss: 0.0764 - val_accuracy: 0.9968\n",
      "Epoch 23/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6381 - accuracy: 0.7773 - val_loss: 0.0894 - val_accuracy: 0.9964\n",
      "Epoch 24/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6393 - accuracy: 0.7779 - val_loss: 0.0732 - val_accuracy: 0.9968\n",
      "Epoch 25/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6360 - accuracy: 0.7772 - val_loss: 0.0762 - val_accuracy: 0.9964\n",
      "Epoch 26/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6387 - accuracy: 0.7769 - val_loss: 0.0735 - val_accuracy: 0.9977\n",
      "Epoch 27/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6353 - accuracy: 0.7773 - val_loss: 0.0512 - val_accuracy: 0.9968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6372 - accuracy: 0.7769 - val_loss: 0.0624 - val_accuracy: 0.9973\n",
      "Epoch 29/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6347 - accuracy: 0.7772 - val_loss: 0.0698 - val_accuracy: 0.9973\n",
      "Epoch 30/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6349 - accuracy: 0.7776 - val_loss: 0.0573 - val_accuracy: 0.9964\n",
      "Epoch 31/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6309 - accuracy: 0.7781 - val_loss: 0.0792 - val_accuracy: 0.9968\n",
      "Epoch 32/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6309 - accuracy: 0.7777 - val_loss: 0.0682 - val_accuracy: 0.9973\n",
      "Epoch 33/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6283 - accuracy: 0.7773 - val_loss: 0.0730 - val_accuracy: 0.9968\n",
      "Epoch 34/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6283 - accuracy: 0.7780 - val_loss: 0.0765 - val_accuracy: 0.9964\n",
      "Epoch 35/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6301 - accuracy: 0.7779 - val_loss: 0.0509 - val_accuracy: 0.9973\n",
      "Epoch 36/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6308 - accuracy: 0.7778 - val_loss: 0.0424 - val_accuracy: 0.9982\n",
      "Epoch 37/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6324 - accuracy: 0.7761 - val_loss: 0.0345 - val_accuracy: 0.9977\n",
      "Epoch 38/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6287 - accuracy: 0.7770 - val_loss: 0.0462 - val_accuracy: 0.9964\n",
      "Epoch 39/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6267 - accuracy: 0.7772 - val_loss: 0.0416 - val_accuracy: 0.9968\n",
      "Epoch 40/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6273 - accuracy: 0.7778 - val_loss: 0.0736 - val_accuracy: 0.9959\n",
      "Epoch 41/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6288 - accuracy: 0.7772 - val_loss: 0.0688 - val_accuracy: 0.9964\n",
      "Epoch 42/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6299 - accuracy: 0.7774 - val_loss: 0.0554 - val_accuracy: 0.9964\n",
      "Epoch 43/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6291 - accuracy: 0.7783 - val_loss: 0.0586 - val_accuracy: 0.9968\n",
      "Epoch 44/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6280 - accuracy: 0.7785 - val_loss: 0.0539 - val_accuracy: 0.9973\n",
      "Epoch 45/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6263 - accuracy: 0.7777 - val_loss: 0.0479 - val_accuracy: 0.9973\n",
      "Epoch 46/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6263 - accuracy: 0.7782 - val_loss: 0.0757 - val_accuracy: 0.9968\n",
      "Epoch 47/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6257 - accuracy: 0.7781 - val_loss: 0.0628 - val_accuracy: 0.9977\n",
      "Epoch 48/50\n",
      "8820/8820 [==============================] - 138s 16ms/step - loss: 0.6250 - accuracy: 0.7788 - val_loss: 0.0635 - val_accuracy: 0.9973\n",
      "Epoch 49/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6254 - accuracy: 0.7782 - val_loss: 0.0616 - val_accuracy: 0.9968\n",
      "Epoch 50/50\n",
      "8820/8820 [==============================] - 137s 16ms/step - loss: 0.6238 - accuracy: 0.7789 - val_loss: 0.0513 - val_accuracy: 0.9973\n",
      "Train on 8820 samples, validate on 2206 samples\n",
      "Epoch 1/10\n",
      "8820/8820 [==============================] - 136s 15ms/step - loss: 0.3654 - accuracy: 0.9720 - val_loss: 0.0625 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "8820/8820 [==============================] - 135s 15ms/step - loss: 0.3376 - accuracy: 0.9748 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "8820/8820 [==============================] - 135s 15ms/step - loss: 0.3186 - accuracy: 0.9748 - val_loss: 0.0372 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "8820/8820 [==============================] - 135s 15ms/step - loss: 0.3173 - accuracy: 0.9748 - val_loss: 0.0336 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "8820/8820 [==============================] - 136s 15ms/step - loss: 0.3002 - accuracy: 0.9748 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "8820/8820 [==============================] - 136s 15ms/step - loss: 0.2916 - accuracy: 0.9748 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "8820/8820 [==============================] - 137s 15ms/step - loss: 0.2872 - accuracy: 0.9748 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "8820/8820 [==============================] - 135s 15ms/step - loss: 0.2802 - accuracy: 0.9748 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "8820/8820 [==============================] - 135s 15ms/step - loss: 0.2730 - accuracy: 0.9748 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "8820/8820 [==============================] - 135s 15ms/step - loss: 0.2741 - accuracy: 0.9748 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Train on 8820 samples, validate on 2206 samples\n",
      "Epoch 1/10\n",
      "8820/8820 [==============================] - 135s 15ms/step - loss: 0.2834 - accuracy: 0.9831 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "8820/8820 [==============================] - 135s 15ms/step - loss: 0.2639 - accuracy: 0.9831 - val_loss: 0.0412 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "8820/8820 [==============================] - 135s 15ms/step - loss: 0.2461 - accuracy: 0.9831 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "8820/8820 [==============================] - 136s 15ms/step - loss: 0.2410 - accuracy: 0.9831 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "8820/8820 [==============================] - 135s 15ms/step - loss: 0.2336 - accuracy: 0.9831 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "8820/8820 [==============================] - 135s 15ms/step - loss: 0.2246 - accuracy: 0.9831 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "8820/8820 [==============================] - 135s 15ms/step - loss: 0.2236 - accuracy: 0.9831 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "8820/8820 [==============================] - 135s 15ms/step - loss: 0.2216 - accuracy: 0.9831 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "8820/8820 [==============================] - 135s 15ms/step - loss: 0.2188 - accuracy: 0.9831 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "8820/8820 [==============================] - 135s 15ms/step - loss: 0.2124 - accuracy: 0.9831 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "prevision shape : (4726, 1)\n",
      "prevision shape ones : (4726, 1)\n",
      "prevision shape negat : (4726, 1)\n",
      "df iterat final shape : (15752, 26)\n",
      "final df Y shape : (15752, 3)\n",
      "df iterat initial shape : (22503, 26)\n",
      "Shape Train X : (15752, 100)\n",
      "Shape Test X : (6751, 100)\n",
      "Shape Y : (15752, 3)\n",
      "Train on 12601 samples, validate on 3151 samples\n",
      "Epoch 1/50\n",
      "12601/12601 [==============================] - 237s 19ms/step - loss: 0.6272 - accuracy: 0.8387 - val_loss: 0.1777 - val_accuracy: 0.9924\n",
      "Epoch 2/50\n",
      "12601/12601 [==============================] - 232s 18ms/step - loss: 0.5812 - accuracy: 0.8422 - val_loss: 0.1509 - val_accuracy: 0.9927\n",
      "Epoch 3/50\n",
      "12601/12601 [==============================] - 227s 18ms/step - loss: 0.5365 - accuracy: 0.8419 - val_loss: 0.1079 - val_accuracy: 0.9917\n",
      "Epoch 4/50\n",
      "12601/12601 [==============================] - 222s 18ms/step - loss: 0.5108 - accuracy: 0.8426 - val_loss: 0.1107 - val_accuracy: 0.9940\n",
      "Epoch 5/50\n",
      "12601/12601 [==============================] - 219s 17ms/step - loss: 0.4954 - accuracy: 0.8430 - val_loss: 0.1068 - val_accuracy: 0.9917\n",
      "Epoch 6/50\n",
      "12601/12601 [==============================] - 216s 17ms/step - loss: 0.4842 - accuracy: 0.8432 - val_loss: 0.0823 - val_accuracy: 0.9937\n",
      "Epoch 7/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4785 - accuracy: 0.8422 - val_loss: 0.0813 - val_accuracy: 0.9927\n",
      "Epoch 8/50\n",
      "12601/12601 [==============================] - 216s 17ms/step - loss: 0.4735 - accuracy: 0.8427 - val_loss: 0.0893 - val_accuracy: 0.9917\n",
      "Epoch 9/50\n",
      "12601/12601 [==============================] - 216s 17ms/step - loss: 0.4740 - accuracy: 0.8430 - val_loss: 0.1082 - val_accuracy: 0.9911\n",
      "Epoch 10/50\n",
      "12601/12601 [==============================] - 217s 17ms/step - loss: 0.4700 - accuracy: 0.8427 - val_loss: 0.0605 - val_accuracy: 0.9933\n",
      "Epoch 11/50\n",
      "12601/12601 [==============================] - 216s 17ms/step - loss: 0.4653 - accuracy: 0.8422 - val_loss: 0.0539 - val_accuracy: 0.9927\n",
      "Epoch 12/50\n",
      "12601/12601 [==============================] - 216s 17ms/step - loss: 0.4612 - accuracy: 0.8432 - val_loss: 0.0487 - val_accuracy: 0.9946\n",
      "Epoch 13/50\n",
      "12601/12601 [==============================] - 216s 17ms/step - loss: 0.4604 - accuracy: 0.8431 - val_loss: 0.0517 - val_accuracy: 0.9940\n",
      "Epoch 14/50\n",
      "12601/12601 [==============================] - 216s 17ms/step - loss: 0.4576 - accuracy: 0.8429 - val_loss: 0.0874 - val_accuracy: 0.9917\n",
      "Epoch 15/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4568 - accuracy: 0.8437 - val_loss: 0.0532 - val_accuracy: 0.9940\n",
      "Epoch 16/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4553 - accuracy: 0.8436 - val_loss: 0.0443 - val_accuracy: 0.9943\n",
      "Epoch 17/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4552 - accuracy: 0.8439 - val_loss: 0.0775 - val_accuracy: 0.9917\n",
      "Epoch 18/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4524 - accuracy: 0.8435 - val_loss: 0.0629 - val_accuracy: 0.9921\n",
      "Epoch 19/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4508 - accuracy: 0.8437 - val_loss: 0.0446 - val_accuracy: 0.9946\n",
      "Epoch 20/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4497 - accuracy: 0.8440 - val_loss: 0.0803 - val_accuracy: 0.9917\n",
      "Epoch 21/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4487 - accuracy: 0.8441 - val_loss: 0.0910 - val_accuracy: 0.9917\n",
      "Epoch 22/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4498 - accuracy: 0.8440 - val_loss: 0.0901 - val_accuracy: 0.9914\n",
      "Epoch 23/50\n",
      "12601/12601 [==============================] - 216s 17ms/step - loss: 0.4470 - accuracy: 0.8439 - val_loss: 0.0673 - val_accuracy: 0.9921\n",
      "Epoch 24/50\n",
      "12601/12601 [==============================] - 216s 17ms/step - loss: 0.4461 - accuracy: 0.8445 - val_loss: 0.0886 - val_accuracy: 0.9917\n",
      "Epoch 25/50\n",
      "12601/12601 [==============================] - 216s 17ms/step - loss: 0.4467 - accuracy: 0.8452 - val_loss: 0.0576 - val_accuracy: 0.9927\n",
      "Epoch 26/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4444 - accuracy: 0.8445 - val_loss: 0.0761 - val_accuracy: 0.9921\n",
      "Epoch 27/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4446 - accuracy: 0.8438 - val_loss: 0.0625 - val_accuracy: 0.9933\n",
      "Epoch 28/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4441 - accuracy: 0.8440 - val_loss: 0.0962 - val_accuracy: 0.9917\n",
      "Epoch 29/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4433 - accuracy: 0.8437 - val_loss: 0.0712 - val_accuracy: 0.9914\n",
      "Epoch 30/50\n",
      "12601/12601 [==============================] - 216s 17ms/step - loss: 0.4459 - accuracy: 0.8439 - val_loss: 0.1055 - val_accuracy: 0.9914\n",
      "Epoch 31/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4426 - accuracy: 0.8438 - val_loss: 0.1258 - val_accuracy: 0.9914\n",
      "Epoch 32/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4418 - accuracy: 0.8443 - val_loss: 0.0808 - val_accuracy: 0.9921\n",
      "Epoch 33/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4424 - accuracy: 0.8437 - val_loss: 0.0667 - val_accuracy: 0.9927\n",
      "Epoch 34/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4403 - accuracy: 0.8451 - val_loss: 0.0928 - val_accuracy: 0.9917\n",
      "Epoch 35/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4431 - accuracy: 0.8439 - val_loss: 0.1062 - val_accuracy: 0.9911\n",
      "Epoch 36/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4390 - accuracy: 0.8442 - val_loss: 0.1231 - val_accuracy: 0.9917\n",
      "Epoch 37/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4394 - accuracy: 0.8439 - val_loss: 0.1070 - val_accuracy: 0.9914\n",
      "Epoch 38/50\n",
      "12601/12601 [==============================] - 216s 17ms/step - loss: 0.4413 - accuracy: 0.8437 - val_loss: 0.0547 - val_accuracy: 0.9937\n",
      "Epoch 39/50\n",
      "12601/12601 [==============================] - 216s 17ms/step - loss: 0.4404 - accuracy: 0.8438 - val_loss: 0.1188 - val_accuracy: 0.9911\n",
      "Epoch 40/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4402 - accuracy: 0.8443 - val_loss: 0.1312 - val_accuracy: 0.9924\n",
      "Epoch 41/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4417 - accuracy: 0.8441 - val_loss: 0.0707 - val_accuracy: 0.9911\n",
      "Epoch 42/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4372 - accuracy: 0.8442 - val_loss: 0.0838 - val_accuracy: 0.9927\n",
      "Epoch 43/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4382 - accuracy: 0.8450 - val_loss: 0.1023 - val_accuracy: 0.9927\n",
      "Epoch 44/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4372 - accuracy: 0.8441 - val_loss: 0.1297 - val_accuracy: 0.9908\n",
      "Epoch 45/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4368 - accuracy: 0.8438 - val_loss: 0.1176 - val_accuracy: 0.9911\n",
      "Epoch 46/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4378 - accuracy: 0.8440 - val_loss: 0.1374 - val_accuracy: 0.9911\n",
      "Epoch 47/50\n",
      "12601/12601 [==============================] - 216s 17ms/step - loss: 0.4391 - accuracy: 0.8444 - val_loss: 0.0887 - val_accuracy: 0.9914\n",
      "Epoch 48/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4390 - accuracy: 0.8446 - val_loss: 0.1342 - val_accuracy: 0.9914\n",
      "Epoch 49/50\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.4382 - accuracy: 0.8443 - val_loss: 0.0935 - val_accuracy: 0.9921\n",
      "Epoch 50/50\n",
      "12601/12601 [==============================] - 216s 17ms/step - loss: 0.4362 - accuracy: 0.8442 - val_loss: 0.0846 - val_accuracy: 0.9917\n",
      "Train on 12601 samples, validate on 3151 samples\n",
      "Epoch 1/10\n",
      "12601/12601 [==============================] - 214s 17ms/step - loss: 0.2754 - accuracy: 0.9806 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "12601/12601 [==============================] - 214s 17ms/step - loss: 0.2380 - accuracy: 0.9824 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.2242 - accuracy: 0.9824 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.2145 - accuracy: 0.9824 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "12601/12601 [==============================] - 215s 17ms/step - loss: 0.2044 - accuracy: 0.9824 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "12601/12601 [==============================] - 213s 17ms/step - loss: 0.2027 - accuracy: 0.9824 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "12601/12601 [==============================] - 213s 17ms/step - loss: 0.1957 - accuracy: 0.9824 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "12601/12601 [==============================] - 213s 17ms/step - loss: 0.1935 - accuracy: 0.9824 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "12601/12601 [==============================] - 213s 17ms/step - loss: 0.1976 - accuracy: 0.9824 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "12601/12601 [==============================] - 213s 17ms/step - loss: 0.1950 - accuracy: 0.9824 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Train on 12601 samples, validate on 3151 samples\n",
      "Epoch 1/10\n",
      "12601/12601 [==============================] - 213s 17ms/step - loss: 0.2108 - accuracy: 0.9882 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "12601/12601 [==============================] - 213s 17ms/step - loss: 0.1831 - accuracy: 0.9882 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "12601/12601 [==============================] - 213s 17ms/step - loss: 0.1729 - accuracy: 0.9882 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12601/12601 [==============================] - 213s 17ms/step - loss: 0.1682 - accuracy: 0.9882 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "12601/12601 [==============================] - 213s 17ms/step - loss: 0.1643 - accuracy: 0.9882 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "12601/12601 [==============================] - 213s 17ms/step - loss: 0.1598 - accuracy: 0.9882 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "12601/12601 [==============================] - 213s 17ms/step - loss: 0.1536 - accuracy: 0.9882 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "12601/12601 [==============================] - 213s 17ms/step - loss: 0.1518 - accuracy: 0.9882 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "12601/12601 [==============================] - 213s 17ms/step - loss: 0.1521 - accuracy: 0.9882 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "12601/12601 [==============================] - 213s 17ms/step - loss: 0.1448 - accuracy: 0.9882 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "prevision shape : (6751, 1)\n",
      "prevision shape ones : (6751, 1)\n",
      "prevision shape negat : (6751, 1)\n",
      "df iterat final shape : (22503, 26)\n",
      "final df Y shape : (22503, 3)\n",
      "df iterat initial shape : (32148, 26)\n",
      "Shape Train X : (22503, 100)\n",
      "Shape Test X : (9645, 100)\n",
      "Shape Y : (22503, 3)\n",
      "Train on 18002 samples, validate on 4501 samples\n",
      "Epoch 1/50\n",
      "18002/18002 [==============================] - 326s 18ms/step - loss: 0.4932 - accuracy: 0.8835 - val_loss: 0.1274 - val_accuracy: 0.9953\n",
      "Epoch 2/50\n",
      "18002/18002 [==============================] - 313s 17ms/step - loss: 0.4387 - accuracy: 0.8877 - val_loss: 0.0567 - val_accuracy: 0.9960\n",
      "Epoch 3/50\n",
      "18002/18002 [==============================] - 307s 17ms/step - loss: 0.3836 - accuracy: 0.8886 - val_loss: 0.0466 - val_accuracy: 0.9951\n",
      "Epoch 4/50\n",
      "18002/18002 [==============================] - 300s 17ms/step - loss: 0.3647 - accuracy: 0.8880 - val_loss: 0.0444 - val_accuracy: 0.9962\n",
      "Epoch 5/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3532 - accuracy: 0.8885 - val_loss: 0.0440 - val_accuracy: 0.9918\n",
      "Epoch 6/50\n",
      "18002/18002 [==============================] - 289s 16ms/step - loss: 0.3463 - accuracy: 0.8880 - val_loss: 0.0267 - val_accuracy: 0.9951\n",
      "Epoch 7/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3394 - accuracy: 0.8885 - val_loss: 0.0434 - val_accuracy: 0.9973\n",
      "Epoch 8/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3366 - accuracy: 0.8885 - val_loss: 0.0339 - val_accuracy: 0.9960\n",
      "Epoch 9/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3331 - accuracy: 0.8887 - val_loss: 0.0207 - val_accuracy: 0.9956\n",
      "Epoch 10/50\n",
      "18002/18002 [==============================] - 289s 16ms/step - loss: 0.3328 - accuracy: 0.8886 - val_loss: 0.0239 - val_accuracy: 0.9947\n",
      "Epoch 11/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3293 - accuracy: 0.8884 - val_loss: 0.0249 - val_accuracy: 0.9962\n",
      "Epoch 12/50\n",
      "18002/18002 [==============================] - 289s 16ms/step - loss: 0.3276 - accuracy: 0.8891 - val_loss: 0.0316 - val_accuracy: 0.9956\n",
      "Epoch 13/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3240 - accuracy: 0.8896 - val_loss: 0.0291 - val_accuracy: 0.9962\n",
      "Epoch 14/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3237 - accuracy: 0.8896 - val_loss: 0.0199 - val_accuracy: 0.9951\n",
      "Epoch 15/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3220 - accuracy: 0.8900 - val_loss: 0.0257 - val_accuracy: 0.9951\n",
      "Epoch 16/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3211 - accuracy: 0.8897 - val_loss: 0.0361 - val_accuracy: 0.9938\n",
      "Epoch 17/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3220 - accuracy: 0.8897 - val_loss: 0.0464 - val_accuracy: 0.9944\n",
      "Epoch 18/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3250 - accuracy: 0.8895 - val_loss: 0.0267 - val_accuracy: 0.9956\n",
      "Epoch 19/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3231 - accuracy: 0.8896 - val_loss: 0.0262 - val_accuracy: 0.9958\n",
      "Epoch 20/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3197 - accuracy: 0.8899 - val_loss: 0.0200 - val_accuracy: 0.9958\n",
      "Epoch 21/50\n",
      "18002/18002 [==============================] - 289s 16ms/step - loss: 0.3161 - accuracy: 0.8901 - val_loss: 0.0372 - val_accuracy: 0.9962\n",
      "Epoch 22/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3155 - accuracy: 0.8900 - val_loss: 0.0387 - val_accuracy: 0.9960\n",
      "Epoch 23/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3150 - accuracy: 0.8890 - val_loss: 0.0194 - val_accuracy: 0.9938\n",
      "Epoch 24/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3164 - accuracy: 0.8902 - val_loss: 0.0357 - val_accuracy: 0.9956\n",
      "Epoch 25/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3125 - accuracy: 0.8903 - val_loss: 0.0351 - val_accuracy: 0.9956\n",
      "Epoch 26/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3131 - accuracy: 0.8905 - val_loss: 0.0376 - val_accuracy: 0.9962\n",
      "Epoch 27/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3124 - accuracy: 0.8906 - val_loss: 0.0461 - val_accuracy: 0.9949\n",
      "Epoch 28/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3112 - accuracy: 0.8906 - val_loss: 0.0560 - val_accuracy: 0.9951\n",
      "Epoch 29/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3122 - accuracy: 0.8905 - val_loss: 0.0356 - val_accuracy: 0.9956\n",
      "Epoch 30/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3143 - accuracy: 0.8896 - val_loss: 0.0206 - val_accuracy: 0.9962\n",
      "Epoch 31/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3118 - accuracy: 0.8905 - val_loss: 0.0345 - val_accuracy: 0.9951\n",
      "Epoch 32/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3106 - accuracy: 0.8904 - val_loss: 0.0308 - val_accuracy: 0.9949\n",
      "Epoch 33/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3113 - accuracy: 0.8905 - val_loss: 0.0384 - val_accuracy: 0.9949\n",
      "Epoch 34/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3085 - accuracy: 0.8905 - val_loss: 0.0404 - val_accuracy: 0.9949\n",
      "Epoch 35/50\n",
      "18002/18002 [==============================] - 289s 16ms/step - loss: 0.3099 - accuracy: 0.8906 - val_loss: 0.0497 - val_accuracy: 0.9944\n",
      "Epoch 36/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3090 - accuracy: 0.8905 - val_loss: 0.0527 - val_accuracy: 0.9949\n",
      "Epoch 37/50\n",
      "18002/18002 [==============================] - 292s 16ms/step - loss: 0.3112 - accuracy: 0.8909 - val_loss: 0.0434 - val_accuracy: 0.9944\n",
      "Epoch 38/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3091 - accuracy: 0.8910 - val_loss: 0.0401 - val_accuracy: 0.9956\n",
      "Epoch 39/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3076 - accuracy: 0.8913 - val_loss: 0.0483 - val_accuracy: 0.9953\n",
      "Epoch 40/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3076 - accuracy: 0.8904 - val_loss: 0.0424 - val_accuracy: 0.9949\n",
      "Epoch 41/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3084 - accuracy: 0.8911 - val_loss: 0.0462 - val_accuracy: 0.9958\n",
      "Epoch 42/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3080 - accuracy: 0.8905 - val_loss: 0.0407 - val_accuracy: 0.9960\n",
      "Epoch 43/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3078 - accuracy: 0.8911 - val_loss: 0.0688 - val_accuracy: 0.9942\n",
      "Epoch 44/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3074 - accuracy: 0.8911 - val_loss: 0.0512 - val_accuracy: 0.9951\n",
      "Epoch 45/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3066 - accuracy: 0.8910 - val_loss: 0.0746 - val_accuracy: 0.9949\n",
      "Epoch 46/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3069 - accuracy: 0.8913 - val_loss: 0.0612 - val_accuracy: 0.9953\n",
      "Epoch 47/50\n",
      "18002/18002 [==============================] - 289s 16ms/step - loss: 0.3081 - accuracy: 0.8908 - val_loss: 0.0805 - val_accuracy: 0.9942\n",
      "Epoch 48/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3074 - accuracy: 0.8906 - val_loss: 0.0727 - val_accuracy: 0.9936\n",
      "Epoch 49/50\n",
      "18002/18002 [==============================] - 290s 16ms/step - loss: 0.3154 - accuracy: 0.8900 - val_loss: 0.0386 - val_accuracy: 0.9964\n",
      "Epoch 50/50\n",
      "18002/18002 [==============================] - 289s 16ms/step - loss: 0.3079 - accuracy: 0.8906 - val_loss: 0.0391 - val_accuracy: 0.9951\n",
      "Train on 18002 samples, validate on 4501 samples\n",
      "Epoch 1/10\n",
      "18002/18002 [==============================] - 288s 16ms/step - loss: 0.1816 - accuracy: 0.9850 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "18002/18002 [==============================] - 287s 16ms/step - loss: 0.1628 - accuracy: 0.9877 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "18002/18002 [==============================] - 287s 16ms/step - loss: 0.1596 - accuracy: 0.9877 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "18002/18002 [==============================] - 286s 16ms/step - loss: 0.1526 - accuracy: 0.9877 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "18002/18002 [==============================] - 286s 16ms/step - loss: 0.1461 - accuracy: 0.9877 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "18002/18002 [==============================] - 286s 16ms/step - loss: 0.1391 - accuracy: 0.9877 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "18002/18002 [==============================] - 286s 16ms/step - loss: 0.1347 - accuracy: 0.9877 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "18002/18002 [==============================] - 286s 16ms/step - loss: 0.1359 - accuracy: 0.9877 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "18002/18002 [==============================] - 287s 16ms/step - loss: 0.1334 - accuracy: 0.9877 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "18002/18002 [==============================] - 286s 16ms/step - loss: 0.1307 - accuracy: 0.9877 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Train on 18002 samples, validate on 4501 samples\n",
      "Epoch 1/10\n",
      "18002/18002 [==============================] - 287s 16ms/step - loss: 0.1432 - accuracy: 0.9917 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "18002/18002 [==============================] - 287s 16ms/step - loss: 0.1267 - accuracy: 0.9917 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "18002/18002 [==============================] - 287s 16ms/step - loss: 0.1176 - accuracy: 0.9917 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "18002/18002 [==============================] - 287s 16ms/step - loss: 0.1177 - accuracy: 0.9917 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "18002/18002 [==============================] - 287s 16ms/step - loss: 0.1170 - accuracy: 0.9917 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "18002/18002 [==============================] - 287s 16ms/step - loss: 0.1173 - accuracy: 0.9917 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "18002/18002 [==============================] - 287s 16ms/step - loss: 0.1089 - accuracy: 0.9917 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "18002/18002 [==============================] - 287s 16ms/step - loss: 0.1098 - accuracy: 0.9917 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "18002/18002 [==============================] - 287s 16ms/step - loss: 0.1080 - accuracy: 0.9917 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "18002/18002 [==============================] - 287s 16ms/step - loss: 0.1058 - accuracy: 0.9917 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "prevision shape : (9645, 1)\n",
      "prevision shape ones : (9645, 1)\n",
      "prevision shape negat : (9645, 1)\n",
      "df iterat final shape : (32148, 26)\n",
      "final df Y shape : (32148, 3)\n",
      "df iterat initial shape : (45926, 26)\n",
      "Shape Train X : (32148, 100)\n",
      "Shape Test X : (13778, 100)\n",
      "Shape Y : (32148, 3)\n",
      "Train on 25718 samples, validate on 6430 samples\n",
      "Epoch 1/50\n",
      "25718/25718 [==============================] - 510s 20ms/step - loss: 0.3885 - accuracy: 0.9165 - val_loss: 0.0718 - val_accuracy: 0.9964\n",
      "Epoch 2/50\n",
      "25718/25718 [==============================] - 503s 20ms/step - loss: 0.3304 - accuracy: 0.9205 - val_loss: 0.0285 - val_accuracy: 0.9955\n",
      "Epoch 3/50\n",
      "25718/25718 [==============================] - 497s 19ms/step - loss: 0.2843 - accuracy: 0.9204 - val_loss: 0.0310 - val_accuracy: 0.9966\n",
      "Epoch 4/50\n",
      "25718/25718 [==============================] - 497s 19ms/step - loss: 0.2666 - accuracy: 0.9207 - val_loss: 0.0485 - val_accuracy: 0.9964\n",
      "Epoch 5/50\n",
      "25718/25718 [==============================] - 495s 19ms/step - loss: 0.2542 - accuracy: 0.9212 - val_loss: 0.0207 - val_accuracy: 0.9947\n",
      "Epoch 6/50\n",
      "25718/25718 [==============================] - 494s 19ms/step - loss: 0.2487 - accuracy: 0.9218 - val_loss: 0.0224 - val_accuracy: 0.9966\n",
      "Epoch 7/50\n",
      "25718/25718 [==============================] - 494s 19ms/step - loss: 0.2418 - accuracy: 0.9218 - val_loss: 0.0203 - val_accuracy: 0.9963\n",
      "Epoch 8/50\n",
      "25718/25718 [==============================] - 487s 19ms/step - loss: 0.2412 - accuracy: 0.9218 - val_loss: 0.0337 - val_accuracy: 0.9944\n",
      "Epoch 9/50\n",
      "25718/25718 [==============================] - 486s 19ms/step - loss: 0.2365 - accuracy: 0.9222 - val_loss: 0.0238 - val_accuracy: 0.9967\n",
      "Epoch 10/50\n",
      "25718/25718 [==============================] - 487s 19ms/step - loss: 0.2348 - accuracy: 0.9222 - val_loss: 0.0189 - val_accuracy: 0.9952\n",
      "Epoch 11/50\n",
      "25718/25718 [==============================] - 487s 19ms/step - loss: 0.2314 - accuracy: 0.9226 - val_loss: 0.0220 - val_accuracy: 0.9963\n",
      "Epoch 12/50\n",
      "25718/25718 [==============================] - 487s 19ms/step - loss: 0.2281 - accuracy: 0.9225 - val_loss: 0.0210 - val_accuracy: 0.9966\n",
      "Epoch 13/50\n",
      "25718/25718 [==============================] - 485s 19ms/step - loss: 0.2275 - accuracy: 0.9234 - val_loss: 0.0240 - val_accuracy: 0.9966\n",
      "Epoch 14/50\n",
      "25718/25718 [==============================] - 479s 19ms/step - loss: 0.2265 - accuracy: 0.9231 - val_loss: 0.0319 - val_accuracy: 0.9942\n",
      "Epoch 15/50\n",
      "25718/25718 [==============================] - 473s 18ms/step - loss: 0.2254 - accuracy: 0.9232 - val_loss: 0.0365 - val_accuracy: 0.9960\n",
      "Epoch 16/50\n",
      "25718/25718 [==============================] - 473s 18ms/step - loss: 0.2250 - accuracy: 0.9231 - val_loss: 0.0269 - val_accuracy: 0.9967\n",
      "Epoch 17/50\n",
      "25718/25718 [==============================] - 466s 18ms/step - loss: 0.2237 - accuracy: 0.9230 - val_loss: 0.0304 - val_accuracy: 0.9963\n",
      "Epoch 18/50\n",
      "25718/25718 [==============================] - 463s 18ms/step - loss: 0.2236 - accuracy: 0.9231 - val_loss: 0.0278 - val_accuracy: 0.9966\n",
      "Epoch 19/50\n",
      "25718/25718 [==============================] - 457s 18ms/step - loss: 0.2207 - accuracy: 0.9233 - val_loss: 0.0248 - val_accuracy: 0.9964\n",
      "Epoch 20/50\n",
      "25718/25718 [==============================] - 451s 18ms/step - loss: 0.2211 - accuracy: 0.9233 - val_loss: 0.0268 - val_accuracy: 0.9956\n",
      "Epoch 21/50\n",
      "25718/25718 [==============================] - 450s 18ms/step - loss: 0.2200 - accuracy: 0.9231 - val_loss: 0.0311 - val_accuracy: 0.9961\n",
      "Epoch 22/50\n",
      "25718/25718 [==============================] - 447s 17ms/step - loss: 0.2192 - accuracy: 0.9232 - val_loss: 0.0362 - val_accuracy: 0.9966\n",
      "Epoch 23/50\n",
      "25718/25718 [==============================] - 448s 17ms/step - loss: 0.2199 - accuracy: 0.9233 - val_loss: 0.0351 - val_accuracy: 0.9964\n",
      "Epoch 24/50\n",
      "25718/25718 [==============================] - 447s 17ms/step - loss: 0.2207 - accuracy: 0.9230 - val_loss: 0.0256 - val_accuracy: 0.9956\n",
      "Epoch 25/50\n",
      "25718/25718 [==============================] - 439s 17ms/step - loss: 0.2178 - accuracy: 0.9236 - val_loss: 0.0222 - val_accuracy: 0.9960\n",
      "Epoch 26/50\n",
      "25718/25718 [==============================] - 435s 17ms/step - loss: 0.2177 - accuracy: 0.9233 - val_loss: 0.0330 - val_accuracy: 0.9960\n",
      "Epoch 27/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2180 - accuracy: 0.9235 - val_loss: 0.0383 - val_accuracy: 0.9960\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2173 - accuracy: 0.9232 - val_loss: 0.0285 - val_accuracy: 0.9953\n",
      "Epoch 29/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2183 - accuracy: 0.9237 - val_loss: 0.0396 - val_accuracy: 0.9966\n",
      "Epoch 30/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2201 - accuracy: 0.9229 - val_loss: 0.0201 - val_accuracy: 0.9964\n",
      "Epoch 31/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2174 - accuracy: 0.9233 - val_loss: 0.0272 - val_accuracy: 0.9963\n",
      "Epoch 32/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2166 - accuracy: 0.9237 - val_loss: 0.0306 - val_accuracy: 0.9964\n",
      "Epoch 33/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2177 - accuracy: 0.9241 - val_loss: 0.0260 - val_accuracy: 0.9961\n",
      "Epoch 34/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2160 - accuracy: 0.9232 - val_loss: 0.0313 - val_accuracy: 0.9967\n",
      "Epoch 35/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2168 - accuracy: 0.9237 - val_loss: 0.0355 - val_accuracy: 0.9963\n",
      "Epoch 36/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2167 - accuracy: 0.9234 - val_loss: 0.0457 - val_accuracy: 0.9961\n",
      "Epoch 37/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2165 - accuracy: 0.9234 - val_loss: 0.0270 - val_accuracy: 0.9963\n",
      "Epoch 38/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2162 - accuracy: 0.9237 - val_loss: 0.0574 - val_accuracy: 0.9960\n",
      "Epoch 39/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2166 - accuracy: 0.9231 - val_loss: 0.0266 - val_accuracy: 0.9941\n",
      "Epoch 40/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2161 - accuracy: 0.9236 - val_loss: 0.0255 - val_accuracy: 0.9960\n",
      "Epoch 41/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2153 - accuracy: 0.9236 - val_loss: 0.0311 - val_accuracy: 0.9961\n",
      "Epoch 42/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2158 - accuracy: 0.9237 - val_loss: 0.0248 - val_accuracy: 0.9967\n",
      "Epoch 43/50\n",
      "25718/25718 [==============================] - 432s 17ms/step - loss: 0.2147 - accuracy: 0.9234 - val_loss: 0.0366 - val_accuracy: 0.9966\n",
      "Epoch 44/50\n",
      "25718/25718 [==============================] - 433s 17ms/step - loss: 0.2151 - accuracy: 0.9237 - val_loss: 0.0380 - val_accuracy: 0.9966\n",
      "Epoch 45/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2158 - accuracy: 0.9236 - val_loss: 0.0325 - val_accuracy: 0.9961\n",
      "Epoch 46/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2140 - accuracy: 0.9237 - val_loss: 0.0388 - val_accuracy: 0.9967\n",
      "Epoch 47/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2166 - accuracy: 0.9236 - val_loss: 0.0331 - val_accuracy: 0.9966\n",
      "Epoch 48/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2155 - accuracy: 0.9234 - val_loss: 0.0376 - val_accuracy: 0.9961\n",
      "Epoch 49/50\n",
      "25718/25718 [==============================] - 432s 17ms/step - loss: 0.2141 - accuracy: 0.9236 - val_loss: 0.0567 - val_accuracy: 0.9969\n",
      "Epoch 50/50\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.2142 - accuracy: 0.9236 - val_loss: 0.0781 - val_accuracy: 0.9970\n",
      "Train on 25718 samples, validate on 6430 samples\n",
      "Epoch 1/10\n",
      "25718/25718 [==============================] - 428s 17ms/step - loss: 0.1282 - accuracy: 0.9902 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "25718/25718 [==============================] - 432s 17ms/step - loss: 0.1146 - accuracy: 0.9914 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.1095 - accuracy: 0.9914 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.1053 - accuracy: 0.9914 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.0998 - accuracy: 0.9914 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "25718/25718 [==============================] - 432s 17ms/step - loss: 0.0956 - accuracy: 0.9914 - val_loss: 5.2783e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.0941 - accuracy: 0.9914 - val_loss: 4.0901e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "25718/25718 [==============================] - 430s 17ms/step - loss: 0.0940 - accuracy: 0.9914 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "25718/25718 [==============================] - 431s 17ms/step - loss: 0.0944 - accuracy: 0.9914 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "25718/25718 [==============================] - 432s 17ms/step - loss: 0.0943 - accuracy: 0.9914 - val_loss: 7.1311e-04 - val_accuracy: 1.0000\n",
      "Train on 25718 samples, validate on 6430 samples\n",
      "Epoch 1/10\n",
      "25718/25718 [==============================] - 430s 17ms/step - loss: 0.1066 - accuracy: 0.9942 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "25718/25718 [==============================] - 429s 17ms/step - loss: 0.0869 - accuracy: 0.9942 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "25718/25718 [==============================] - 429s 17ms/step - loss: 0.0833 - accuracy: 0.9942 - val_loss: 9.1456e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "25718/25718 [==============================] - 430s 17ms/step - loss: 0.0822 - accuracy: 0.9942 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "25718/25718 [==============================] - 430s 17ms/step - loss: 0.0766 - accuracy: 0.9942 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "25718/25718 [==============================] - 430s 17ms/step - loss: 0.0759 - accuracy: 0.9942 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "25718/25718 [==============================] - 430s 17ms/step - loss: 0.0761 - accuracy: 0.9942 - val_loss: 7.2744e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "25718/25718 [==============================] - 430s 17ms/step - loss: 0.0739 - accuracy: 0.9942 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "25718/25718 [==============================] - 429s 17ms/step - loss: 0.0724 - accuracy: 0.9942 - val_loss: 4.1876e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "25718/25718 [==============================] - 429s 17ms/step - loss: 0.0732 - accuracy: 0.9942 - val_loss: 2.7799e-04 - val_accuracy: 1.0000\n",
      "prevision shape : (13778, 1)\n",
      "prevision shape ones : (13778, 1)\n",
      "prevision shape negat : (13778, 1)\n",
      "df iterat final shape : (45926, 26)\n",
      "final df Y shape : (45926, 3)\n"
     ]
    }
   ],
   "source": [
    "## Iteration Algorithm for the RNN\n",
    "\n",
    "while n < 40000:\n",
    "    \n",
    "    starting_train_iterat, starting_test_iterat = train_test_division(starting_df_iterat, final_df, (0.7, 0.3))\n",
    "    \n",
    "    df_iterat = pd.concat([starting_train_iterat, starting_test_iterat])\n",
    "    n = df_iterat.shape[0]\n",
    "    \n",
    "#    if n >= 10000:\n",
    "#        print(f'Do you want to continue? ({n} articles classified)')\n",
    "#        inp = input()\n",
    "#        if inp == 'Y':\n",
    "#            break\n",
    "#        else:\n",
    "#            continue\n",
    "    \n",
    "    try:\n",
    "        word_embedding_df_i = word_embedding(pd.concat([starting_train_iterat, starting_test_iterat]))\n",
    "    except:\n",
    "        pass\n",
    "    max_features = word_embedding_df_i.shape[0]\n",
    "    \n",
    "    starting_train_X_i = starting_train_iterat['Article Text']\n",
    "    starting_test_X_i = starting_test_iterat['Article Text']\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(list(starting_train_X_i))\n",
    "    train_X_i = tokenizer.texts_to_sequences(starting_train_X_i)\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(list(starting_test_X_i))\n",
    "    test_X_i = tokenizer.texts_to_sequences(starting_test_X_i)\n",
    "    \n",
    "    print(f'df iterat initial shape : {df_iterat.shape}')\n",
    "    ## Pad the sequences\n",
    "    train_X_i = pad_sequences(train_X_i, maxlen=maxlen)\n",
    "    print(f'Shape Train X : {train_X_i.shape}')\n",
    "    test_X_i = pad_sequences(test_X_i, maxlen=maxlen)\n",
    "    print(f'Shape Test X : {test_X_i.shape}')\n",
    "    print(f'Shape Y : {df_Y_i.shape}')\n",
    "    \n",
    "    embedding_matrix = np.mean([word_embedding_df_i], axis = 0)\n",
    "    \n",
    "    model = model_bilstm_attention(embedding_matrix)\n",
    "    \n",
    "    for i in range(3):\n",
    "        if i == 0:\n",
    "            res_i_ones = model.fit(train_X_i, df_Y_i[:, i], validation_split=0.2, epochs=50, class_weight = class_weight)\n",
    "            \n",
    "            acc_i = res_i_ones.history['accuracy'][-1]\n",
    "            val_i = res_i_ones.history['val_accuracy'][-1]\n",
    "            accuracy_l.append(acc_i)\n",
    "            validation_l.append(val_i)\n",
    "            pred_test_x_i = model.predict(test_X_i)\n",
    "            pred_test_X_round_i = np.round(pred_test_x_i, decimals=0)\n",
    "\n",
    "            \n",
    "            \n",
    "        elif i == 1:\n",
    "            res_i_pos = model.fit(train_X_i, df_Y_i[:, i], validation_split=0.2, epochs=10, class_weight = class_weight_positives)\n",
    "            \n",
    "            acc_i = res_i_pos.history['accuracy'][-1]\n",
    "            val_i = res_i_pos.history['val_accuracy'][-1]\n",
    "            accuracy_ones_l.append(acc_i)\n",
    "            validation_ones_l.append(val_i)\n",
    "            pred_test_x_ones_i = model.predict(test_X_i)\n",
    "            pred_test_X_ones_round_i = np.round(pred_test_x_ones_i, decimals=0)\n",
    "\n",
    "            \n",
    "        elif i == 2:\n",
    "            res_i_neg = model.fit(train_X_i, df_Y_i[:, i], validation_split=0.2, epochs=10, class_weight = class_weight_negatives)\n",
    "            \n",
    "            acc_i = res_i_neg.history['accuracy'][-1]\n",
    "            val_i = res_i_neg.history['val_accuracy'][-1]\n",
    "            accuracy_negatives_l.append(acc_i)\n",
    "            validation_negatives_l.append(val_i)\n",
    "            pred_test_x_negatives_i = model.predict(test_X_i)\n",
    "            pred_test_X_negatives_round_i = np.round(pred_test_x_negatives_i, decimals=0)\n",
    "    \n",
    "    print(f'prevision shape : {pred_test_X_round_i.shape}')\n",
    "    print(f'prevision shape ones : {pred_test_X_ones_round_i.shape}')\n",
    "    print(f'prevision shape negat : {pred_test_X_negatives_round_i.shape}')\n",
    "    \n",
    "    test_pred_Y_i = np.hstack((pred_test_X_round_i, pred_test_X_ones_round_i, pred_test_X_negatives_round_i))\n",
    "    df_Y_i = np.vstack((starting_df_Y, test_pred_Y_i))\n",
    "    \n",
    "    starting_df_Y = df_Y_i\n",
    "    starting_df_iterat = df_iterat\n",
    "    print(f'df iterat final shape : {starting_df_iterat.shape}')\n",
    "    print(f'final df Y shape : {df_Y_i.shape}')\n",
    "    \n",
    "    iterat += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dynamic alg. : 9\n"
     ]
    }
   ],
   "source": [
    "## Checking the number of iterations and adding the first to the scores\n",
    "\n",
    "accuracy_l = [acc_pred] + accuracy_l\n",
    "accuracy_ones_l = [acc_pos_pred] + accuracy_ones_l\n",
    "accuracy_negatives_l = [acc_neg_pred] + accuracy_negatives_l\n",
    "\n",
    "validation_l = [test_acc_pred] + validation_l\n",
    "validation_ones_l = [test_acc_pos_pred] + validation_ones_l\n",
    "validation_negatives_l = [test_acc_neg_pred] + validation_negatives_l\n",
    "\n",
    "print(f'Number of dynamic alg. : {iterat}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6525096,\n",
       " 0.54760295,\n",
       " 0.6167297,\n",
       " 0.58895504,\n",
       " 0.6137468,\n",
       " 0.6920959,\n",
       " 0.7789116,\n",
       " 0.84421873,\n",
       " 0.8905677,\n",
       " 0.9236333]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7915058,\n",
       " 0.8501013,\n",
       " 0.89508504,\n",
       " 0.9265873,\n",
       " 0.948623,\n",
       " 0.9640428,\n",
       " 0.9748299,\n",
       " 0.98238236,\n",
       " 0.98766804,\n",
       " 0.99136794]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_ones_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.85907334,\n",
       " 0.8993923,\n",
       " 0.92958415,\n",
       " 0.9507275,\n",
       " 0.9655172,\n",
       " 0.97586656,\n",
       " 0.98310655,\n",
       " 0.9881756,\n",
       " 0.9917231,\n",
       " 0.99420637]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_negatives_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4692307710647583,\n",
       " 0.7547169923782349,\n",
       " 0.5603773593902588,\n",
       " 0.8309115171432495,\n",
       " 0.9426456689834595,\n",
       " 0.9870466589927673,\n",
       " 0.9972801208496094,\n",
       " 0.9917486310005188,\n",
       " 0.9951121807098389,\n",
       " 0.99704509973526]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9769230484962463, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_ones_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9884615540504456, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_negatives_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 8 + 1 iterations to plot. Let us plot the first 10 iterations with accuracy test, accuracy train\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "iterat = list(range(1, 11))    \n",
    "\n",
    "data = ((iterat, accuracy_l[:10]), (iterat, validation_l[:10]), (iterat, accuracy_ones_l[:10]), \n",
    "        (iterat, validation_ones_l[:10]), (iterat, accuracy_negatives_l[:10]), (iterat, validation_negatives_l[:10]))\n",
    "colors = ('blue', 'red',\n",
    "          'green', 'black',\n",
    "          'yellow', 'brown')\n",
    "groups = ('Accuracy Train 0', 'Accuracy Test 0', 'Accuracy Train 1', 'Accuracy Test 1', 'Accuracy Train -1', 'Accuracy Test -1')\n",
    "\n",
    "fig= plt.figure(figsize=(30,15))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "for dat, color, group in zip(data, colors, groups):\n",
    "    x, y = dat\n",
    "    ax.plot(x, y, c=color, label=group)\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Accuracy Train and Test')\n",
    "plt.title('Result First Iterations Dynamic RNN')\n",
    "plt.show()\n",
    "plt.savefig('RNN Italian Articles First 9 Iterations Plot.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Converting the 46000 articles into sentiment column\n",
    "\n",
    "sentiment = []\n",
    "\n",
    "for y in df_Y_i:\n",
    "    neutr = y[0]\n",
    "    pos = y[1]\n",
    "    neg = y[2]\n",
    "    if neutr == 1:\n",
    "        if sum([pos, neg]) < 1:\n",
    "            sentiment.append(0)\n",
    "        else:\n",
    "            if pos == 1 and neg == 0:\n",
    "                sentiment.append(1)\n",
    "            elif neg == 1 and pos == 0:\n",
    "                sentiment.append(-1)\n",
    "            elif neg == 1 and pos == 1:\n",
    "                sentiment.append(np.random.choice([-1, 1]))\n",
    "    elif neutr == 0 and sum([pos, neg]) < 1:\n",
    "        sentiment.append(np.random.randint(-1, 2))\n",
    "    elif neutr == 0 and sum([pos, neg]) >= 1:\n",
    "        if pos == 1 and neg == 0:\n",
    "            sentiment.append(1)\n",
    "        elif neg == 1 and pos == 0:\n",
    "            sentiment.append(-1)\n",
    "        elif neg == 1 and pos == 1:\n",
    "                sentiment.append(np.random.choice([-1, 1]))\n",
    "\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Final distribution of sentiment')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## plotting distribution of sentiment\n",
    "\n",
    "plt.hist(sentiment, color='black')\n",
    "plt.title('Final distribution of sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1.0\n",
       "1       -1.0\n",
       "2        1.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "54665    NaN\n",
       "54666    NaN\n",
       "54667    NaN\n",
       "54668    NaN\n",
       "54669    NaN\n",
       "Name: Sentiment, Length: 54670, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## including the variable in the dataset\n",
    "\n",
    "final_df['Sentiment'].iloc[:len(sentiment)] = sentiment\n",
    "\n",
    "final_df['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing Nan and saving the file\n",
    "\n",
    "final_df = final_df.dropna(subset=['Sentiment'])\n",
    "\n",
    "final_df.to_excel('Final Dataset Italian Articles Classified.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
